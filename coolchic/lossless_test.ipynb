{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30588d7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/jakub/ETH/2025_2026_fall/thesis/Cool-Chic/coolchic/../datasets/kodak/kodim01.png', '/home/jakub/ETH/2025_2026_fall/thesis/Cool-Chic/coolchic/../datasets/kodak/kodim02.png', '/home/jakub/ETH/2025_2026_fall/thesis/Cool-Chic/coolchic/../datasets/kodak/kodim03.png', '/home/jakub/ETH/2025_2026_fall/thesis/Cool-Chic/coolchic/../datasets/kodak/kodim04.png', '/home/jakub/ETH/2025_2026_fall/thesis/Cool-Chic/coolchic/../datasets/kodak/kodim05.png', '/home/jakub/ETH/2025_2026_fall/thesis/Cool-Chic/coolchic/../datasets/kodak/kodim06.png', '/home/jakub/ETH/2025_2026_fall/thesis/Cool-Chic/coolchic/../datasets/kodak/kodim07.png', '/home/jakub/ETH/2025_2026_fall/thesis/Cool-Chic/coolchic/../datasets/kodak/kodim08.png', '/home/jakub/ETH/2025_2026_fall/thesis/Cool-Chic/coolchic/../datasets/kodak/kodim09.png', '/home/jakub/ETH/2025_2026_fall/thesis/Cool-Chic/coolchic/../datasets/kodak/kodim10.png', '/home/jakub/ETH/2025_2026_fall/thesis/Cool-Chic/coolchic/../datasets/kodak/kodim11.png', '/home/jakub/ETH/2025_2026_fall/thesis/Cool-Chic/coolchic/../datasets/kodak/kodim12.png', '/home/jakub/ETH/2025_2026_fall/thesis/Cool-Chic/coolchic/../datasets/kodak/kodim13.png', '/home/jakub/ETH/2025_2026_fall/thesis/Cool-Chic/coolchic/../datasets/kodak/kodim14.png', '/home/jakub/ETH/2025_2026_fall/thesis/Cool-Chic/coolchic/../datasets/kodak/kodim15.png', '/home/jakub/ETH/2025_2026_fall/thesis/Cool-Chic/coolchic/../datasets/kodak/kodim16.png', '/home/jakub/ETH/2025_2026_fall/thesis/Cool-Chic/coolchic/../datasets/kodak/kodim17.png', '/home/jakub/ETH/2025_2026_fall/thesis/Cool-Chic/coolchic/../datasets/kodak/kodim18.png', '/home/jakub/ETH/2025_2026_fall/thesis/Cool-Chic/coolchic/../datasets/kodak/kodim19.png', '/home/jakub/ETH/2025_2026_fall/thesis/Cool-Chic/coolchic/../datasets/kodak/kodim20.png', '/home/jakub/ETH/2025_2026_fall/thesis/Cool-Chic/coolchic/../datasets/kodak/kodim21.png', '/home/jakub/ETH/2025_2026_fall/thesis/Cool-Chic/coolchic/../datasets/kodak/kodim22.png', '/home/jakub/ETH/2025_2026_fall/thesis/Cool-Chic/coolchic/../datasets/kodak/kodim23.png', '/home/jakub/ETH/2025_2026_fall/thesis/Cool-Chic/coolchic/../datasets/kodak/kodim24.png']\n",
      "{'input': '/home/jakub/ETH/2025_2026_fall/thesis/Cool-Chic/coolchic/../datasets/kodak/kodim01.png', 'output': '/home/jakub/ETH/2025_2026_fall/thesis/Cool-Chic/coolchic/test-workdir//output', 'workdir': '/home/jakub/ETH/2025_2026_fall/thesis/Cool-Chic/coolchic/test-workdir/', 'lmbda': 0.001, 'job_duration_min': -1, 'print_detailed_archi': False, 'print_detailed_struct': False, 'start_lr': 0.01, 'n_itr': 1, 'n_itr_pretrain_motion': 1, 'n_train_loops': 1, 'preset': 'debug', 'layers_synthesis_residue': '16-1-linear-relu,X-1-linear-none,X-3-residual-relu,X-3-residual-none', 'arm_residue': '8,2', 'n_ft_per_res_residue': '1,1,1,1,1,1,1', 'ups_k_size_residue': 8, 'ups_preconcat_k_size_residue': 7}\n",
      "----------\n",
      "\n",
      "\n",
      "*----------------------------------------------------------------------------------------------------------*\n",
      "|                                                                                                          |\n",
      "|                                                                                                          |\n",
      "|       ,gggg,                                                                                             |\n",
      "|     ,88\"\"\"Y8b,                           ,dPYb,                             ,dPYb,                       |\n",
      "|    d8\"     `Y8                           IP'`Yb                             IP'`Yb                       |\n",
      "|   d8'   8b  d8                           I8  8I                             I8  8I      gg               |\n",
      "|  ,8I    \"Y88P'                           I8  8'                             I8  8'      \"\"               |\n",
      "|  I8'             ,ggggg,      ,ggggg,    I8 dP      aaaaaaaa        ,gggg,  I8 dPgg,    gg     ,gggg,    |\n",
      "|  d8             dP\"  \"Y8ggg  dP\"  \"Y8ggg I8dP       \"\"\"\"\"\"\"\"       dP\"  \"Yb I8dP\" \"8I   88    dP\"  \"Yb   |\n",
      "|  Y8,           i8'    ,8I   i8'    ,8I   I8P                      i8'       I8P    I8   88   i8'         |\n",
      "|  `Yba,,_____, ,d8,   ,d8'  ,d8,   ,d8'  ,d8b,_                   ,d8,_    _,d8     I8,_,88,_,d8,_    _   |\n",
      "|    `\"Y8888888 P\"Y8888P\"    P\"Y8888P\"    8P'\"Y88                  P\"\"Y8888PP88P     `Y88P\"\"Y8P\"\"Y8888PP   |\n",
      "|                                                                                                          |\n",
      "|                                                                                                          |\n",
      "| version 4.1.0, July 2025                                                              ¬© 2023-2025 Orange |\n",
      "*----------------------------------------------------------------------------------------------------------*\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "\n",
    "sys.path.append(os.getcwd())\n",
    "\n",
    "import torch\n",
    "from lossless.component.coolchic import CoolChicEncoderParameter\n",
    "from lossless.component.frame import load_frame_encoder\n",
    "from lossless.component.types import NAME_COOLCHIC_ENC\n",
    "from lossless.component.image import (\n",
    "    FrameEncoderManager,\n",
    "    encode_one_frame,\n",
    ")\n",
    "from enc.utils.codingstructure import CodingStructure, Frame\n",
    "from typing import Any, Dict, List\n",
    "from lossless.component.coolchic import CoolChicEncoder\n",
    "\n",
    "DATASET_PATH = f\"{os.getcwd()}/../datasets/kodak\"\n",
    "IMAGE_PATHS = sorted(\n",
    "    glob.glob(f\"{DATASET_PATH}/*.png\"),\n",
    "    key=lambda x: int(os.path.basename(x).split(\".\")[0][len(\"kodim\") :]),\n",
    ")\n",
    "TEST_WORKDIR = f\"{os.getcwd()}/test-workdir/\"\n",
    "PATH_COOL_CHIC_CFG = f\"{os.getcwd()}/../cfg/\"\n",
    "print(IMAGE_PATHS)\n",
    "\n",
    "args = {\n",
    "    # not in config files\n",
    "    \"input\": IMAGE_PATHS[0],\n",
    "    \"output\": TEST_WORKDIR + \"/output\",\n",
    "    \"workdir\": TEST_WORKDIR,\n",
    "    \"lmbda\": 1e-3,\n",
    "    \"job_duration_min\": -1,\n",
    "    \"print_detailed_archi\": False,\n",
    "    \"print_detailed_struct\": False,\n",
    "    # config file paths\n",
    "    # encoder side\n",
    "    \"start_lr\": 1e-2,\n",
    "    \"n_itr\": 1,\n",
    "    \"n_itr_pretrain_motion\": 1,\n",
    "    \"n_train_loops\": 1,\n",
    "    \"preset\": \"debug\",\n",
    "    # decoder side\n",
    "    \"layers_synthesis_residue\": \"16-1-linear-relu,X-1-linear-none,X-3-residual-relu,X-3-residual-none\",\n",
    "    \"arm_residue\": \"8,2\",\n",
    "    \"n_ft_per_res_residue\": \"1,1,1,1,1,1,1\",\n",
    "    \"ups_k_size_residue\": 8,\n",
    "    \"ups_preconcat_k_size_residue\": 7,\n",
    "}\n",
    "\n",
    "print(args)\n",
    "print(\"----------\")\n",
    "# os.chdir(args[\"workdir\"])\n",
    "\n",
    "start_print = (\n",
    "    \"\\n\\n\"\n",
    "    \"*----------------------------------------------------------------------------------------------------------*\\n\"\n",
    "    \"|                                                                                                          |\\n\"\n",
    "    \"|                                                                                                          |\\n\"\n",
    "    \"|       ,gggg,                                                                                             |\\n\"\n",
    "    '|     ,88\"\"\"Y8b,                           ,dPYb,                             ,dPYb,                       |\\n'\n",
    "    \"|    d8\\\"     `Y8                           IP'`Yb                             IP'`Yb                       |\\n\"\n",
    "    \"|   d8'   8b  d8                           I8  8I                             I8  8I      gg               |\\n\"\n",
    "    \"|  ,8I    \\\"Y88P'                           I8  8'                             I8  8'      \\\"\\\"               |\\n\"\n",
    "    \"|  I8'             ,ggggg,      ,ggggg,    I8 dP      aaaaaaaa        ,gggg,  I8 dPgg,    gg     ,gggg,    |\\n\"\n",
    "    '|  d8             dP\"  \"Y8ggg  dP\"  \"Y8ggg I8dP       \"\"\"\"\"\"\"\"       dP\"  \"Yb I8dP\" \"8I   88    dP\"  \"Yb   |\\n'\n",
    "    \"|  Y8,           i8'    ,8I   i8'    ,8I   I8P                      i8'       I8P    I8   88   i8'         |\\n\"\n",
    "    \"|  `Yba,,_____, ,d8,   ,d8'  ,d8,   ,d8'  ,d8b,_                   ,d8,_    _,d8     I8,_,88,_,d8,_    _   |\\n\"\n",
    "    '|    `\"Y8888888 P\"Y8888P\"    P\"Y8888P\"    8P\\'\"Y88                  P\"\"Y8888PP88P     `Y88P\"\"Y8P\"\"Y8888PP   |\\n'\n",
    "    \"|                                                                                                          |\\n\"\n",
    "    \"|                                                                                                          |\\n\"\n",
    "    \"| version 4.1.0, July 2025                                                              ¬© 2023-2025 Orange |\\n\"\n",
    "    \"*----------------------------------------------------------------------------------------------------------*\\n\"\n",
    ")\n",
    "print(start_print)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ab56161",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UTIL CODE\n",
    "\n",
    "def pretty_str_dict(d: dict[str, Any]) -> str:\n",
    "    if not d:\n",
    "        return \"\"\n",
    "    \n",
    "    # Find length of the longest key\n",
    "    max_key_len = max(len(k) for k in d.keys())\n",
    "    \n",
    "    lines = []\n",
    "    for key, value in d.items():\n",
    "        # Pad key so values align, ensure at least one space after colon\n",
    "        lines.append(f\"{key}:{' ' * (max_key_len - len(key) + 1)}{value}\")\n",
    "    \n",
    "    return \"\\n\".join(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97c1f988",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COOL CHICK PARAMETER PARSER CODE\n",
    "def parse_synthesis_layers(layers_synthesis: str) -> List[str]:\n",
    "    \"\"\"The layers of the synthesis are presented in as a coma-separated string.\n",
    "    This simply splits up the different substrings and return them.\n",
    "\n",
    "    Args:\n",
    "        layers_synthesis (str): Command line argument for the synthesis.\n",
    "\n",
    "    Returns:\n",
    "        List[str]: List of string where the i-th element described the i-th\n",
    "            synthesis layer\n",
    "    \"\"\"\n",
    "    parsed_layer_synth = [x for x in layers_synthesis.split(\",\") if x != \"\"]\n",
    "\n",
    "    assert parsed_layer_synth, (\n",
    "        \"Synthesis should have at least one layer, found nothing. \\n\"\n",
    "        f\"--layers_synthesis={layers_synthesis} does not work!\\n\"\n",
    "        \"Try something like 32-1-linear-relu,X-1-linear-none,\"\n",
    "        \"X-3-residual-relu,X-3-residual-none\"\n",
    "    )\n",
    "\n",
    "    return parsed_layer_synth\n",
    "\n",
    "\n",
    "def parse_n_ft_per_res(n_ft_per_res: str) -> list[int]:\n",
    "    \"\"\"The number of feature per resolution is a coma-separated string.\n",
    "    This simply splits up the different substrings and return them.\n",
    "\n",
    "    Args:\n",
    "        n_ft_per_res (str): Something like \"1,1,1,1,1,1,1\" for 7 latent grids\n",
    "        with different resolution and 1 feature each.\n",
    "\n",
    "    Returns:\n",
    "        List[int]: The i-th element is the number of features for the i-th\n",
    "        latent, i.e. the latent of a resolution (H / 2^i, W / 2^i).\n",
    "    \"\"\"\n",
    "\n",
    "    n_ft_per_res_int = [int(x) for x in n_ft_per_res.split(\",\") if x != \"\"]\n",
    "    # assert set(n_ft_per_res) == {\n",
    "    #     1\n",
    "    # }, f\"--n_ft_per_res should only contains 1. Found {n_ft_per_res}\"\n",
    "    return n_ft_per_res_int\n",
    "\n",
    "\n",
    "def parse_arm_archi(arm: str) -> Dict[str, int]:\n",
    "    \"\"\"The arm is described as <dim_arm>,<n_hidden_layers_arm>.\n",
    "    Split up this string to return the value as a dict.\n",
    "\n",
    "    Args:\n",
    "        arm (str): Command line argument for the ARM.\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, int]: The ARM architecture\n",
    "    \"\"\"\n",
    "    assert len(arm.split(\",\")) == 2, (\n",
    "        f\"--arm format should be X,Y.\" f\" Found {arm}\"\n",
    "    )\n",
    "\n",
    "    dim_arm, n_hidden_layers_arm = [int(x) for x in arm.split(\",\")]\n",
    "    arm_param = {\"dim_arm\": dim_arm, \"n_hidden_layers_arm\": n_hidden_layers_arm}\n",
    "    return arm_param\n",
    "\n",
    "\n",
    "def get_coolchic_param_from_args(\n",
    "    args: dict,\n",
    "    coolchic_enc_name: str,\n",
    ") -> Dict[str, Any]:\n",
    "    layers_synthesis = parse_synthesis_layers(\n",
    "        args[f\"layers_synthesis_{coolchic_enc_name}\"]\n",
    "    )\n",
    "    n_ft_per_res = parse_n_ft_per_res(args[f\"n_ft_per_res_{coolchic_enc_name}\"])\n",
    "\n",
    "    coolchic_param = {\n",
    "        \"layers_synthesis\": layers_synthesis,\n",
    "        \"n_ft_per_res\": n_ft_per_res,\n",
    "        \"ups_k_size\": args[f\"ups_k_size_{coolchic_enc_name}\"],\n",
    "        \"ups_preconcat_k_size\": args[\n",
    "            f\"ups_preconcat_k_size_{coolchic_enc_name}\"\n",
    "        ],\n",
    "    }\n",
    "\n",
    "    # Add ARM parameters\n",
    "    coolchic_param.update(parse_arm_archi(args[f\"arm_{coolchic_enc_name}\"]))\n",
    "\n",
    "    return coolchic_param\n",
    "\n",
    "def change_n_out_synth(layers_synth: List[str], n_out: int) -> List[str]:\n",
    "        \"\"\"Change the number of output features in the list of strings\n",
    "        describing the synthesis architecture. It replaces \"X\" with n_out. E.g.\n",
    "\n",
    "        From [8-1-linear-relu,X-1-linear-none,X-3-residual-none]\n",
    "        To   [8-1-linear-relu,2-1-linear-none,2-3-residual-none]\n",
    "\n",
    "        If n_out = 2\n",
    "\n",
    "        Args:\n",
    "            layers_synth (List[str]): List of strings describing the different\n",
    "                synthesis layers\n",
    "            n_out (int): Number of desired output.\n",
    "\n",
    "        Returns:\n",
    "            List[str]: List of strings with the proper number of output features.\n",
    "        \"\"\"\n",
    "        return [lay.replace(\"X\", str(n_out)) for lay in layers_synth]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14db32c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing /home/jakub/ETH/2025_2026_fall/thesis/Cool-Chic/coolchic/test-workdir/...\n"
     ]
    }
   ],
   "source": [
    "# remove the content of the workdir if it exists\n",
    "if os.path.exists(args[\"workdir\"]):\n",
    "    print(f\"Removing {args['workdir']}...\")\n",
    "    for file in os.listdir(args[\"workdir\"]):\n",
    "        file_path = os.path.join(args[\"workdir\"], file)\n",
    "        try:\n",
    "            if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "                os.unlink(file_path)\n",
    "            elif os.path.isdir(file_path):\n",
    "                os.rmdir(file_path)\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to delete {file_path}. Reason: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a790acd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CoolChicEncoder(\n",
       "  (latent_grids): ParameterList(\n",
       "      (0): Parameter containing: [torch.float32 of size 1x1x768x512]\n",
       "      (1): Parameter containing: [torch.float32 of size 1x1x384x256]\n",
       "      (2): Parameter containing: [torch.float32 of size 1x1x192x128]\n",
       "      (3): Parameter containing: [torch.float32 of size 1x1x96x64]\n",
       "      (4): Parameter containing: [torch.float32 of size 1x1x48x32]\n",
       "      (5): Parameter containing: [torch.float32 of size 1x1x24x16]\n",
       "      (6): Parameter containing: [torch.float32 of size 1x1x12x8]\n",
       "  )\n",
       "  (synthesis): Synthesis(\n",
       "    (synth_branches): ModuleList()\n",
       "    (layers): Sequential(\n",
       "      (0): SynthesisConv2d()\n",
       "      (1): ReLU()\n",
       "      (2): SynthesisConv2d()\n",
       "      (3): Identity()\n",
       "      (4): SynthesisConv2d()\n",
       "      (5): ReLU()\n",
       "      (6): SynthesisConv2d()\n",
       "      (7): Identity()\n",
       "    )\n",
       "  )\n",
       "  (upsampling): Upsampling(\n",
       "    (conv_transpose2ds): ModuleList(\n",
       "      (0-5): 6 x ParametrizedUpsamplingSeparableSymmetricConvTranspose2d(\n",
       "        (parametrizations): ModuleDict(\n",
       "          (weight): ParametrizationList(\n",
       "            (0): _Parameterization_Symmetric_1d()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (conv2ds): ModuleList(\n",
       "      (0-5): 6 x ParametrizedUpsamplingSeparableSymmetricConv2d(\n",
       "        (parametrizations): ModuleDict(\n",
       "          (weight): ParametrizationList(\n",
       "            (0): _Parameterization_Symmetric_1d()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (arm): Arm(\n",
       "    (mlp): Sequential(\n",
       "      (0): ArmLinear()\n",
       "      (1): ReLU()\n",
       "      (2): ArmLinear()\n",
       "      (3): ReLU()\n",
       "      (4): ArmLinear()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "encoder_param = CoolChicEncoderParameter(\n",
    "    **get_coolchic_param_from_args(args, \"residue\")\n",
    ")\n",
    "encoder_param.set_image_size((768, 512))\n",
    "encoder_param.layers_synthesis = change_n_out_synth(\n",
    "    encoder_param.layers_synthesis, 6\n",
    ")\n",
    "\n",
    "coolchic = CoolChicEncoder(param=encoder_param)\n",
    "coolchic.eval()\n",
    "\n",
    "# print(coolchic.pretty_string(True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "789c05f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random prior: dict_keys(['raw_out', 'rate', 'additional_data'])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    # Forward pass with no quantization noise\n",
    "    # This is a random prior, i.e. the output is not conditioned on any input\n",
    "    # image.\n",
    "    random_prior = coolchic.forward(\n",
    "            quantizer_noise_type=\"none\",\n",
    "            quantizer_type=\"hardround\",\n",
    "            AC_MAX_VAL=-1,\n",
    "            flag_additional_outputs=False,\n",
    "        )\n",
    "print(f\"Random prior: {random_prior.keys()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6cd923a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 6, 768, 512])\n",
      "torch.Size([524256])\n",
      "tensor(0.) tensor(0.)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(random_prior[\"raw_out\"].size())\n",
    "print(random_prior[\"rate\"].size())\n",
    "# print(random_prior[\"additional_data\"])\n",
    "print(torch.min(random_prior[\"raw_out\"]), torch.max(random_prior[\"raw_out\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0610560",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ PERFORMING COOL CHIC FORWARD PASS (ENCODING + DECODING)\n",
      "============================================================\n",
      "‚úÖ Decoding completed!\n",
      "   Input latent grids: 7 hierarchical levels\n",
      "   Decoded image shape: torch.Size([1, 3, 768, 512])\n",
      "   Pixel value range: [0.000, 0.000]\n",
      "   Total rate: 0.0 bits\n",
      "   Clamped pixel range: [0.000, 0.000]\n",
      "\n",
      "üéØ KEY POINTS:\n",
      "   ‚Ä¢ coolchic() performs complete encoding+decoding pipeline\n",
      "   ‚Ä¢ output['raw_out'] contains the decoded RGB image\n",
      "   ‚Ä¢ output['rate'] contains compression rate information\n",
      "   ‚Ä¢ For lossy: synthesis outputs RGB pixels directly\n",
      "   ‚Ä¢ For lossless: synthesis should output distribution parameters\n"
     ]
    }
   ],
   "source": [
    "# DECODING WITH COOL CHIC ENCODER\n",
    "# The CoolChicEncoder.forward() method performs the complete encoding process\n",
    "# and returns a CoolChicEncoderOutput containing the decoded image\n",
    "\n",
    "print(\"üîÑ PERFORMING COOL CHIC FORWARD PASS (ENCODING + DECODING)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Put the encoder in evaluation mode for inference\n",
    "coolchic.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Forward pass through the Cool Chic encoder\n",
    "    # This performs the complete encoding and decoding pipeline:\n",
    "    # 1. Quantize latent variables\n",
    "    # 2. ARM predicts latent distributions for rate calculation  \n",
    "    # 3. Upsampling takes latents to full resolution\n",
    "    # 4. Synthesis converts features to RGB pixels\n",
    "    \n",
    "    output = coolchic()\n",
    "    \n",
    "    # Extract the decoded image from the output\n",
    "    decoded_image = output[\"raw_out\"]  # [1, 3, H, W] tensor\n",
    "    rate_bits = output[\"rate\"]         # Rate in bits for compression\n",
    "    \n",
    "    print(f\"‚úÖ Decoding completed!\")\n",
    "    print(f\"   Input latent grids: {len(coolchic.latent_grids)} hierarchical levels\")\n",
    "    print(f\"   Decoded image shape: {decoded_image.shape}\")\n",
    "    print(f\"   Pixel value range: [{decoded_image.min():.3f}, {decoded_image.max():.3f}]\")\n",
    "    print(f\"   Total rate: {rate_bits.sum():.1f} bits\")\n",
    "    \n",
    "    # The decoded image is now ready to use!\n",
    "    # For visualization, clamp to valid range [0, 1]\n",
    "    decoded_pixels = torch.clamp(decoded_image, 0.0, 1.0)\n",
    "    print(f\"   Clamped pixel range: [{decoded_pixels.min():.3f}, {decoded_pixels.max():.3f}]\")\n",
    "\n",
    "print(\"\\nüéØ KEY POINTS:\")\n",
    "print(\"   ‚Ä¢ coolchic() performs complete encoding+decoding pipeline\")\n",
    "print(\"   ‚Ä¢ output['raw_out'] contains the decoded RGB image\")\n",
    "print(\"   ‚Ä¢ output['rate'] contains compression rate information\")\n",
    "print(\"   ‚Ä¢ For lossy: synthesis outputs RGB pixels directly\")\n",
    "print(\"   ‚Ä¢ For lossless: synthesis should output distribution parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e35e5298",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîß MANUAL DECODING STEP-BY-STEP\n",
      "==================================================\n",
      "Step 1: LATENT VARIABLES (learned representation)\n",
      "   Grid 0: torch.Size([1, 1, 768, 512]) - mean=0.0000, std=0.0000\n",
      "   Grid 1: torch.Size([1, 1, 384, 256]) - mean=0.0000, std=0.0000\n",
      "   Grid 2: torch.Size([1, 1, 192, 128]) - mean=0.0000, std=0.0000\n",
      "   Grid 3: torch.Size([1, 1, 96, 64]) - mean=0.0000, std=0.0000\n",
      "   Grid 4: torch.Size([1, 1, 48, 32]) - mean=0.0000, std=0.0000\n",
      "   Grid 5: torch.Size([1, 1, 24, 16]) - mean=0.0000, std=0.0000\n",
      "   Grid 6: torch.Size([1, 1, 12, 8]) - mean=0.0000, std=0.0000\n",
      "\n",
      "Step 2: AUTO-REGRESSIVE MODULE (ARM)\n",
      "   ‚Üí Predicts probability distributions (Œº, œÉ) for each latent\n",
      "   ‚Üí ARM processes spatial context to predict latent statistics\n",
      "   ARM architecture: 16-D hidden layers\n",
      "\n",
      "Step 3: UPSAMPLING NETWORK\n",
      "   ‚Üí Takes hierarchical latents and upsamples to full resolution\n",
      "   Input: 7 grids at different resolutions\n",
      "   Output: torch.Size([1, 7, 768, 512]) (full resolution features)\n",
      "\n",
      "Step 4: SYNTHESIS NETWORK ‚≠ê KEY FOR LOSSLESS\n",
      "   ‚Üí Current: Outputs RGB pixel values directly\n",
      "   ‚Üí For lossless: Should output logistic distribution parameters\n",
      "   Current output shape: torch.Size([1, 3, 768, 512])\n",
      "   Range: [0.000, 0.000]\n",
      "\n",
      "üí° FOR LOSSLESS COMPRESSION:\n",
      "   ‚Ä¢ Steps 1-3 stay the same\n",
      "   ‚Ä¢ Step 4 (Synthesis) should output distribution parameters instead of pixels\n",
      "   ‚Ä¢ Then use entropy coding to get exact pixel values\n",
      "\n",
      "üîÑ HOW TO USE FOR DECODING:\n",
      "   1. Call coolchic() to get decoded image: output = coolchic()\n",
      "   2. Extract image: decoded_img = output['raw_out']\n",
      "   3. Clamp to valid range: final_img = torch.clamp(decoded_img, 0, 1)\n",
      "   4. Convert to numpy if needed: img_np = final_img.squeeze().permute(1,2,0).numpy()\n"
     ]
    }
   ],
   "source": [
    "# MANUAL STEP-BY-STEP DECODING BREAKDOWN\n",
    "print(\"\\nüîß MANUAL DECODING STEP-BY-STEP\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "with torch.no_grad():\n",
    "    print(\"Step 1: LATENT VARIABLES (learned representation)\")\n",
    "    latent_grids = [grid.data for grid in coolchic.latent_grids]\n",
    "    for i, grid in enumerate(latent_grids):\n",
    "        print(f\"   Grid {i}: {grid.shape} - mean={grid.mean():.4f}, std={grid.std():.4f}\")\n",
    "    \n",
    "    print(\"\\nStep 2: AUTO-REGRESSIVE MODULE (ARM)\")\n",
    "    print(\"   ‚Üí Predicts probability distributions (Œº, œÉ) for each latent\")\n",
    "    print(\"   ‚Üí ARM processes spatial context to predict latent statistics\")\n",
    "    print(f\"   ARM architecture: {coolchic.param.dim_arm}-D hidden layers\")\n",
    "    \n",
    "    print(\"\\nStep 3: UPSAMPLING NETWORK\")\n",
    "    print(\"   ‚Üí Takes hierarchical latents and upsamples to full resolution\")\n",
    "    upsampled_features = coolchic.upsampling(latent_grids)\n",
    "    print(f\"   Input: {len(latent_grids)} grids at different resolutions\")\n",
    "    print(f\"   Output: {upsampled_features.shape} (full resolution features)\")\n",
    "    \n",
    "    print(\"\\nStep 4: SYNTHESIS NETWORK ‚≠ê KEY FOR LOSSLESS\")\n",
    "    print(\"   ‚Üí Current: Outputs RGB pixel values directly\")\n",
    "    print(\"   ‚Üí For lossless: Should output logistic distribution parameters\")\n",
    "    synthesized_output = coolchic.synthesis(upsampled_features)\n",
    "    print(f\"   Current output shape: {synthesized_output.shape}\")\n",
    "    print(f\"   Range: [{synthesized_output.min():.3f}, {synthesized_output.max():.3f}]\")\n",
    "    \n",
    "    # Final resize to image dimensions if needed\n",
    "    if synthesized_output.shape[-2:] != coolchic.param.img_size:\n",
    "        final_output = torch.nn.functional.interpolate(\n",
    "            synthesized_output, \n",
    "            size=coolchic.param.img_size, \n",
    "            mode=\"nearest\"\n",
    "        )\n",
    "        print(f\"   Resized to: {final_output.shape}\")\n",
    "    else:\n",
    "        final_output = synthesized_output\n",
    "    \n",
    "print(\"\\nüí° FOR LOSSLESS COMPRESSION:\")\n",
    "print(\"   ‚Ä¢ Steps 1-3 stay the same\")\n",
    "print(\"   ‚Ä¢ Step 4 (Synthesis) should output distribution parameters instead of pixels\")\n",
    "print(\"   ‚Ä¢ Then use entropy coding to get exact pixel values\")\n",
    "\n",
    "print(\"\\nüîÑ HOW TO USE FOR DECODING:\")\n",
    "print(\"   1. Call coolchic() to get decoded image: output = coolchic()\")\n",
    "print(\"   2. Extract image: decoded_img = output['raw_out']\")\n",
    "print(\"   3. Clamp to valid range: final_img = torch.clamp(decoded_img, 0, 1)\")\n",
    "print(\"   4. Convert to numpy if needed: img_np = final_img.squeeze().permute(1,2,0).numpy()\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c1d4c0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üñºÔ∏è PRACTICAL DECODING EXAMPLE\n",
      "========================================\n",
      "Loading image: /home/jakub/ETH/2025_2026_fall/thesis/Cool-Chic/coolchic/../datasets/kodak/kodim01.png\n",
      "Original image shape: torch.Size([1, 3, 512, 768])\n",
      "Pixel range: [0.000, 1.000]\n",
      "\n",
      "üîß Initializing latent grids with random values...\n",
      "   Grid 0: std=0.1001\n",
      "   Grid 1: std=0.1000\n",
      "   Grid 2: std=0.0998\n",
      "   Grid 3: std=0.1003\n",
      "   Grid 4: std=0.0978\n",
      "   Grid 5: std=0.1101\n",
      "   Grid 6: std=0.1032\n",
      "\n",
      "üöÄ PERFORMING DECODING...\n",
      "‚úÖ Decoding successful!\n",
      "   Decoded shape: torch.Size([1, 3, 768, 512])\n",
      "   Pixel range: [0.000, 0.000]\n",
      "   Rate: 6373600.5 bits\n",
      "\n",
      "üìä SUMMARY:\n",
      "   ‚Ä¢ Input: torch.Size([1, 3, 512, 768]) original image\n",
      "   ‚Ä¢ Output: torch.Size([1, 3, 768, 512]) decoded image\n",
      "   ‚Ä¢ The synthesis network converted 7 features ‚Üí 3 RGB channels\n",
      "   ‚Ä¢ This is the core of the Cool-Chic decoder!\n"
     ]
    }
   ],
   "source": [
    "# PRACTICAL EXAMPLE: LOAD IMAGE AND DECODE\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "print(\"üñºÔ∏è PRACTICAL DECODING EXAMPLE\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Check if we have access to an image\n",
    "if IMAGE_PATHS:\n",
    "    print(f\"Loading image: {IMAGE_PATHS[0]}\")\n",
    "    \n",
    "    # Load and preprocess the image\n",
    "    img = Image.open(IMAGE_PATHS[0]).convert('RGB')\n",
    "    img_array = np.array(img).astype(np.float32) / 255.0\n",
    "    \n",
    "    # Convert to PyTorch tensor [1, 3, H, W]\n",
    "    img_tensor = torch.from_numpy(img_array).permute(2, 0, 1).unsqueeze(0)\n",
    "    \n",
    "    print(f\"Original image shape: {img_tensor.shape}\")\n",
    "    print(f\"Pixel range: [{img_tensor.min():.3f}, {img_tensor.max():.3f}]\")\n",
    "    \n",
    "    # Initialize latent grids with some non-zero values for demo\n",
    "    # (In practice, these would be optimized during training)\n",
    "    print(\"\\nüîß Initializing latent grids with random values...\")\n",
    "    for i, grid in enumerate(coolchic.latent_grids):\n",
    "        grid.data.normal_(0, 0.1)  # Small random initialization\n",
    "        print(f\"   Grid {i}: std={grid.data.std():.4f}\")\n",
    "    \n",
    "    # Now perform decoding\n",
    "    print(\"\\nüöÄ PERFORMING DECODING...\")\n",
    "    coolchic.eval()\n",
    "    with torch.no_grad():\n",
    "        output = coolchic()\n",
    "        decoded_image = output[\"raw_out\"]\n",
    "        rate_bits = output[\"rate\"]\n",
    "        \n",
    "        print(f\"‚úÖ Decoding successful!\")\n",
    "        print(f\"   Decoded shape: {decoded_image.shape}\")\n",
    "        print(f\"   Pixel range: [{decoded_image.min():.3f}, {decoded_image.max():.3f}]\")\n",
    "        print(f\"   Rate: {rate_bits.sum():.1f} bits\")\n",
    "        \n",
    "        # Clamp to valid range\n",
    "        decoded_clamped = torch.clamp(decoded_image, 0.0, 1.0)\n",
    "        \n",
    "    print(\"\\nüìä SUMMARY:\")\n",
    "    print(f\"   ‚Ä¢ Input: {img_tensor.shape} original image\")\n",
    "    print(f\"   ‚Ä¢ Output: {decoded_clamped.shape} decoded image\")\n",
    "    print(f\"   ‚Ä¢ The synthesis network converted {coolchic.upsampling(latent_grids).shape[1]} features ‚Üí 3 RGB channels\")\n",
    "    print(f\"   ‚Ä¢ This is the core of the Cool-Chic decoder!\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No images found in IMAGE_PATHS\")\n",
    "    print(\"   But the decoding process works the same way:\")\n",
    "    print(\"   1. Initialize/load latent grids\")\n",
    "    print(\"   2. Call coolchic() to decode\")\n",
    "    print(\"   3. Extract output['raw_out'] as your decoded image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f612af5",
   "metadata": {},
   "source": [
    "## üéØ Key Takeaways: How to Use Cool Chic for Decoding\n",
    "\n",
    "### **The Cool Chic Decoder Pipeline:**\n",
    "\n",
    "1. **Latent Variables** ‚Üí Hierarchical grids at multiple resolutions (learned during training)\n",
    "2. **ARM (Auto-Regressive Module)** ‚Üí Predicts probability distributions for entropy coding\n",
    "3. **Upsampling Network** ‚Üí Converts hierarchical latents to full resolution features  \n",
    "4. **Synthesis Network** ‚Üí Converts features to final output (RGB pixels for lossy, distribution parameters for lossless)\n",
    "\n",
    "### **How to Decode with Cool Chic:**\n",
    "\n",
    "```python\n",
    "# Basic decoding\n",
    "coolchic.eval()\n",
    "with torch.no_grad():\n",
    "    output = coolchic()\n",
    "    decoded_image = output[\"raw_out\"]  # [1, 3, H, W] tensor\n",
    "    rate_bits = output[\"rate\"]         # Compression rate\n",
    "    \n",
    "    # Clamp to valid pixel range\n",
    "    final_image = torch.clamp(decoded_image, 0.0, 1.0)\n",
    "```\n",
    "\n",
    "### **For Your Lossless Work:**\n",
    "\n",
    "- **Keep**: Latent variables, ARM, Upsampling (steps 1-3)\n",
    "- **Modify**: Synthesis network (step 4) to output **distribution parameters** instead of RGB pixels\n",
    "- **Add**: Entropy decoder to convert distribution parameters ‚Üí exact pixel values\n",
    "\n",
    "The Cool Chic encoder you've initialized is ready to use! The `coolchic()` call performs the complete encoding+decoding pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aace33fa",
   "metadata": {},
   "source": [
    "## ü§î Key Conceptual Difference: Cool-Chic vs Traditional Deep Learning\n",
    "\n",
    "### **Traditional Deep Learning:**\n",
    "```python\n",
    "# Traditional approach - model processes input to produce output\n",
    "model = SomeNeuralNetwork()\n",
    "output = model(input_image)  # Input ‚Üí Processing ‚Üí Output\n",
    "```\n",
    "\n",
    "### **Cool-Chic Approach:**\n",
    "```python\n",
    "# Cool-Chic - model BECOMES the compressed representation of ONE specific image\n",
    "coolchic = CoolChicEncoder()  # This IS the compressed image\n",
    "output = coolchic()           # No input needed - latents ARE the image data\n",
    "```\n",
    "\n",
    "### **The Fundamental Difference:**\n",
    "\n",
    "- **Traditional**: One model processes many images\n",
    "- **Cool-Chic**: One model PER image (the model IS the compressed image)\n",
    "\n",
    "Each Cool-Chic encoder is trained specifically for ONE image and contains that image's compressed representation in its latent grids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "61a14066",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ COMPLETE COOL-CHIC COMPRESSION WORKFLOW\n",
      "==================================================\n",
      "STEP 1: TRAINING (Per Image)\n",
      "   ‚Ä¢ Input: ONE specific image (e.g., kodim01.png)\n",
      "   ‚Ä¢ Process: Optimize latent grids + networks to reconstruct THAT image\n",
      "   ‚Ä¢ Output: Trained CoolChicEncoder that can recreate the original image\n",
      "   ‚Ä¢ Loss: MSE(decoded_image, original_image) + Œª * rate\n",
      "\n",
      "STEP 2: BITSTREAM CREATION\n",
      "   ‚Ä¢ Quantize neural network weights (ARM, Upsampling, Synthesis)\n",
      "   ‚Ä¢ Entropy encode quantized weights ‚Üí neural network bitstream\n",
      "   ‚Ä¢ Quantize latent variables\n",
      "   ‚Ä¢ Entropy encode latents using ARM predictions ‚Üí latent bitstream\n",
      "   ‚Ä¢ Combine both ‚Üí final compressed file\n",
      "\n",
      "STEP 3: DECODING\n",
      "   ‚Ä¢ Read bitstream ‚Üí reconstruct neural networks + latent grids\n",
      "   ‚Ä¢ Run decoder: latents ‚Üí upsampling ‚Üí synthesis ‚Üí image\n",
      "\n",
      "üí° KEY INSIGHT:\n",
      "   The latent grids contain the ACTUAL IMAGE DATA (compressed)\n",
      "   The neural networks are the DECODER for that specific image\n",
      "   Both are saved in the bitstream!\n",
      "\n",
      "üìÅ WHAT'S IN THE BITSTREAM:\n",
      "   1. Neural network weights (ARM, Upsampling, Synthesis)\n",
      "   2. Latent variable values\n",
      "   3. Quantization parameters\n",
      "   4. Architecture information\n"
     ]
    }
   ],
   "source": [
    "# THE COMPLETE COOL-CHIC WORKFLOW\n",
    "print(\"üîÑ COMPLETE COOL-CHIC COMPRESSION WORKFLOW\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(\"STEP 1: TRAINING (Per Image)\")\n",
    "print(\"   ‚Ä¢ Input: ONE specific image (e.g., kodim01.png)\")\n",
    "print(\"   ‚Ä¢ Process: Optimize latent grids + networks to reconstruct THAT image\")\n",
    "print(\"   ‚Ä¢ Output: Trained CoolChicEncoder that can recreate the original image\")\n",
    "print(\"   ‚Ä¢ Loss: MSE(decoded_image, original_image) + Œª * rate\")\n",
    "\n",
    "print(\"\\nSTEP 2: BITSTREAM CREATION\")\n",
    "print(\"   ‚Ä¢ Quantize neural network weights (ARM, Upsampling, Synthesis)\")\n",
    "print(\"   ‚Ä¢ Entropy encode quantized weights ‚Üí neural network bitstream\")\n",
    "print(\"   ‚Ä¢ Quantize latent variables\")\n",
    "print(\"   ‚Ä¢ Entropy encode latents using ARM predictions ‚Üí latent bitstream\")\n",
    "print(\"   ‚Ä¢ Combine both ‚Üí final compressed file\")\n",
    "\n",
    "print(\"\\nSTEP 3: DECODING\")\n",
    "print(\"   ‚Ä¢ Read bitstream ‚Üí reconstruct neural networks + latent grids\")\n",
    "print(\"   ‚Ä¢ Run decoder: latents ‚Üí upsampling ‚Üí synthesis ‚Üí image\")\n",
    "\n",
    "print(\"\\nüí° KEY INSIGHT:\")\n",
    "print(\"   The latent grids contain the ACTUAL IMAGE DATA (compressed)\")\n",
    "print(\"   The neural networks are the DECODER for that specific image\")\n",
    "print(\"   Both are saved in the bitstream!\")\n",
    "\n",
    "print(\"\\nüìÅ WHAT'S IN THE BITSTREAM:\")\n",
    "print(\"   1. Neural network weights (ARM, Upsampling, Synthesis)\")\n",
    "print(\"   2. Latent variable values\") \n",
    "print(\"   3. Quantization parameters\")\n",
    "print(\"   4. Architecture information\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "12ffb709",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ BITSTREAM SAVING & LOADING PROCESS\n",
      "=============================================\n",
      "üîß ENCODING PROCESS (Image ‚Üí Bitstream):\n",
      "   1. Load original image\n",
      "   2. Initialize CoolChicEncoder with random latents & networks\n",
      "   3. TRAIN the encoder to reconstruct the specific image:\n",
      "      ‚Üí Optimize latent grids to contain compressed image data\n",
      "      ‚Üí Optimize networks (ARM, upsampling, synthesis) as decoder\n",
      "   4. Quantize everything for bitstream compatibility\n",
      "   5. Save to bitstream file (.cool)\n",
      "\n",
      "üìÇ DECODING PROCESS (Bitstream ‚Üí Image):\n",
      "   1. Read bitstream file\n",
      "   2. Reconstruct neural networks from saved weights\n",
      "   3. Reconstruct latent grids from saved values\n",
      "   4. Run forward pass: latents ‚Üí networks ‚Üí decoded image\n",
      "\n",
      "üéØ ANALOGY:\n",
      "   Think of it like a puzzle:\n",
      "   ‚Ä¢ Latent grids = puzzle pieces (the data)\n",
      "   ‚Ä¢ Neural networks = instructions how to assemble pieces (the decoder)\n",
      "   ‚Ä¢ Bitstream = box containing both pieces AND instructions\n",
      "   ‚Ä¢ Decoding = following instructions to assemble the image\n",
      "\n",
      "üîç PRACTICAL EXAMPLE:\n",
      "   For kodim01.png:\n",
      "   ‚Ä¢ Training: Fit encoder to recreate kodim01.png perfectly\n",
      "   ‚Ä¢ Bitstream: Save trained encoder weights + latent values\n",
      "   ‚Ä¢ Decoding: Load encoder, run forward pass ‚Üí get kodim01.png back\n",
      "\n",
      "üìä CURRENT ENCODER STATE:\n",
      "   ‚Ä¢ Latent grids: 7 grids with 524256 total values\n",
      "   ‚Ä¢ ARM parameters: 578 weights\n",
      "   ‚Ä¢ Upsampling parameters: 60 weights\n",
      "   ‚Ä¢ Synthesis parameters: 523 weights\n",
      "   ALL of these get saved in the bitstream!\n"
     ]
    }
   ],
   "source": [
    "# HOW BITSTREAM SAVING/LOADING WORKS\n",
    "print(\"üíæ BITSTREAM SAVING & LOADING PROCESS\")\n",
    "print(\"=\" * 45)\n",
    "\n",
    "print(\"üîß ENCODING PROCESS (Image ‚Üí Bitstream):\")\n",
    "print(\"   1. Load original image\")\n",
    "print(\"   2. Initialize CoolChicEncoder with random latents & networks\")\n",
    "print(\"   3. TRAIN the encoder to reconstruct the specific image:\")\n",
    "print(\"      ‚Üí Optimize latent grids to contain compressed image data\")\n",
    "print(\"      ‚Üí Optimize networks (ARM, upsampling, synthesis) as decoder\")\n",
    "print(\"   4. Quantize everything for bitstream compatibility\")\n",
    "print(\"   5. Save to bitstream file (.cool)\")\n",
    "\n",
    "print(\"\\nüìÇ DECODING PROCESS (Bitstream ‚Üí Image):\")\n",
    "print(\"   1. Read bitstream file\")\n",
    "print(\"   2. Reconstruct neural networks from saved weights\")\n",
    "print(\"   3. Reconstruct latent grids from saved values\") \n",
    "print(\"   4. Run forward pass: latents ‚Üí networks ‚Üí decoded image\")\n",
    "\n",
    "print(\"\\nüéØ ANALOGY:\")\n",
    "print(\"   Think of it like a puzzle:\")\n",
    "print(\"   ‚Ä¢ Latent grids = puzzle pieces (the data)\")\n",
    "print(\"   ‚Ä¢ Neural networks = instructions how to assemble pieces (the decoder)\")\n",
    "print(\"   ‚Ä¢ Bitstream = box containing both pieces AND instructions\")\n",
    "print(\"   ‚Ä¢ Decoding = following instructions to assemble the image\")\n",
    "\n",
    "print(\"\\nüîç PRACTICAL EXAMPLE:\")\n",
    "print(\"   For kodim01.png:\")\n",
    "print(\"   ‚Ä¢ Training: Fit encoder to recreate kodim01.png perfectly\")\n",
    "print(\"   ‚Ä¢ Bitstream: Save trained encoder weights + latent values\")\n",
    "print(\"   ‚Ä¢ Decoding: Load encoder, run forward pass ‚Üí get kodim01.png back\")\n",
    "\n",
    "# Let's see what the encoder looks like when it's actually trained\n",
    "print(f\"\\nüìä CURRENT ENCODER STATE:\")\n",
    "print(f\"   ‚Ä¢ Latent grids: {len(coolchic.latent_grids)} grids with {sum(g.numel() for g in coolchic.latent_grids)} total values\")\n",
    "print(f\"   ‚Ä¢ ARM parameters: {sum(p.numel() for p in coolchic.arm.parameters())} weights\")\n",
    "print(f\"   ‚Ä¢ Upsampling parameters: {sum(p.numel() for p in coolchic.upsampling.parameters())} weights\")\n",
    "print(f\"   ‚Ä¢ Synthesis parameters: {sum(p.numel() for p in coolchic.synthesis.parameters())} weights\")\n",
    "print(\"   ALL of these get saved in the bitstream!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1e8a4518",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìö DETAILED COOL-CHIC TRAINING & BITSTREAM EXPLANATION\n",
      "============================================================\n",
      "‚ùì YOUR CONFUSION IS TOTALLY VALID!\n",
      "   Traditional ML: model.predict(image) ‚Üí output\n",
      "   Cool-Chic: model() ‚Üí decoded_image (no input needed!)\n",
      "   Why? Because the model IS the compressed image!\n",
      "\n",
      "üéØ THE CORE CONCEPT:\n",
      "   ‚Ä¢ Each image gets its OWN dedicated neural network\n",
      "   ‚Ä¢ The network's weights + latent grids = compressed representation\n",
      "   ‚Ä¢ Training optimizes BOTH networks AND latents for ONE specific image\n",
      "\n",
      "üîÑ STEP-BY-STEP WORKFLOW:\n",
      "\n",
      "1Ô∏è‚É£ TRAINING PHASE (Per Image)\n",
      "   Input: Original image (e.g., kodim01.png)\n",
      "   Goal: Find latent grids + network weights that recreate THIS image\n",
      "   Loss: MSE(decoded, original) + Œª √ó rate\n",
      "   Process:\n",
      "   ‚îÇ\n",
      "   ‚îú‚îÄ Initialize random latent grids\n",
      "   ‚îú‚îÄ Initialize random network weights (ARM, Upsampling, Synthesis)\n",
      "   ‚îú‚îÄ For many iterations:\n",
      "   ‚îÇ  ‚îú‚îÄ Forward: latents ‚Üí networks ‚Üí decoded image\n",
      "   ‚îÇ  ‚îú‚îÄ Compute loss vs original image\n",
      "   ‚îÇ  ‚îú‚îÄ Backward: update latents + network weights\n",
      "   ‚îÇ  ‚îî‚îÄ Repeat until convergence\n",
      "   ‚îî‚îÄ Result: Trained encoder that perfectly reconstructs the image\n",
      "\n",
      "2Ô∏è‚É£ BITSTREAM CREATION\n",
      "   Input: Trained CoolChicEncoder\n",
      "   Goal: Save everything needed to recreate the image\n",
      "   Process:\n",
      "   ‚îÇ\n",
      "   ‚îú‚îÄ Quantize neural network weights\n",
      "   ‚îú‚îÄ Entropy encode quantized weights ‚Üí neural network bitstream\n",
      "   ‚îú‚îÄ Quantize latent variable values\n",
      "   ‚îú‚îÄ Use ARM to predict latent distributions\n",
      "   ‚îú‚îÄ Entropy encode latents using ARM predictions ‚Üí latent bitstream\n",
      "   ‚îî‚îÄ Combine everything ‚Üí final .cool file\n",
      "\n",
      "3Ô∏è‚É£ DECODING PHASE\n",
      "   Input: .cool bitstream file\n",
      "   Goal: Recreate the original image\n",
      "   Process:\n",
      "   ‚îÇ\n",
      "   ‚îú‚îÄ Read bitstream ‚Üí extract network weights + latent values\n",
      "   ‚îú‚îÄ Reconstruct neural networks (ARM, Upsampling, Synthesis)\n",
      "   ‚îú‚îÄ Reconstruct latent grids\n",
      "   ‚îî‚îÄ Forward pass: latents ‚Üí networks ‚Üí decoded image\n",
      "\n",
      "üí° KEY INSIGHTS:\n",
      "   ‚Ä¢ NO prediction function - the model CONTAINS the image data\n",
      "   ‚Ä¢ Latent grids = compressed pixel data\n",
      "   ‚Ä¢ Networks = learned decoder for those specific latents\n",
      "   ‚Ä¢ Both are saved in bitstream and needed for decoding\n",
      "   ‚Ä¢ Each .cool file is a complete decoder for ONE specific image\n"
     ]
    }
   ],
   "source": [
    "# DETAILED EXPLANATION: TRAINING AND BITSTREAM PROCESS\n",
    "print(\"üìö DETAILED COOL-CHIC TRAINING & BITSTREAM EXPLANATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"‚ùì YOUR CONFUSION IS TOTALLY VALID!\")\n",
    "print(\"   Traditional ML: model.predict(image) ‚Üí output\")\n",
    "print(\"   Cool-Chic: model() ‚Üí decoded_image (no input needed!)\")\n",
    "print(\"   Why? Because the model IS the compressed image!\")\n",
    "\n",
    "print(\"\\nüéØ THE CORE CONCEPT:\")\n",
    "print(\"   ‚Ä¢ Each image gets its OWN dedicated neural network\")\n",
    "print(\"   ‚Ä¢ The network's weights + latent grids = compressed representation\")\n",
    "print(\"   ‚Ä¢ Training optimizes BOTH networks AND latents for ONE specific image\")\n",
    "\n",
    "print(\"\\nüîÑ STEP-BY-STEP WORKFLOW:\")\n",
    "print(\"\\n1Ô∏è‚É£ TRAINING PHASE (Per Image)\")\n",
    "print(\"   Input: Original image (e.g., kodim01.png)\")\n",
    "print(\"   Goal: Find latent grids + network weights that recreate THIS image\")\n",
    "print(\"   Loss: MSE(decoded, original) + Œª √ó rate\")\n",
    "print(\"   Process:\")\n",
    "print(\"   ‚îÇ\")\n",
    "print(\"   ‚îú‚îÄ Initialize random latent grids\")\n",
    "print(\"   ‚îú‚îÄ Initialize random network weights (ARM, Upsampling, Synthesis)\")\n",
    "print(\"   ‚îú‚îÄ For many iterations:\")\n",
    "print(\"   ‚îÇ  ‚îú‚îÄ Forward: latents ‚Üí networks ‚Üí decoded image\")\n",
    "print(\"   ‚îÇ  ‚îú‚îÄ Compute loss vs original image\")\n",
    "print(\"   ‚îÇ  ‚îú‚îÄ Backward: update latents + network weights\")\n",
    "print(\"   ‚îÇ  ‚îî‚îÄ Repeat until convergence\")\n",
    "print(\"   ‚îî‚îÄ Result: Trained encoder that perfectly reconstructs the image\")\n",
    "\n",
    "print(\"\\n2Ô∏è‚É£ BITSTREAM CREATION\")\n",
    "print(\"   Input: Trained CoolChicEncoder\")\n",
    "print(\"   Goal: Save everything needed to recreate the image\")\n",
    "print(\"   Process:\")\n",
    "print(\"   ‚îÇ\")\n",
    "print(\"   ‚îú‚îÄ Quantize neural network weights\")\n",
    "print(\"   ‚îú‚îÄ Entropy encode quantized weights ‚Üí neural network bitstream\")\n",
    "print(\"   ‚îú‚îÄ Quantize latent variable values\")\n",
    "print(\"   ‚îú‚îÄ Use ARM to predict latent distributions\")\n",
    "print(\"   ‚îú‚îÄ Entropy encode latents using ARM predictions ‚Üí latent bitstream\")\n",
    "print(\"   ‚îî‚îÄ Combine everything ‚Üí final .cool file\")\n",
    "\n",
    "print(\"\\n3Ô∏è‚É£ DECODING PHASE\")\n",
    "print(\"   Input: .cool bitstream file\")\n",
    "print(\"   Goal: Recreate the original image\")\n",
    "print(\"   Process:\")\n",
    "print(\"   ‚îÇ\")\n",
    "print(\"   ‚îú‚îÄ Read bitstream ‚Üí extract network weights + latent values\")\n",
    "print(\"   ‚îú‚îÄ Reconstruct neural networks (ARM, Upsampling, Synthesis)\")\n",
    "print(\"   ‚îú‚îÄ Reconstruct latent grids\")\n",
    "print(\"   ‚îî‚îÄ Forward pass: latents ‚Üí networks ‚Üí decoded image\")\n",
    "\n",
    "print(\"\\nüí° KEY INSIGHTS:\")\n",
    "print(\"   ‚Ä¢ NO prediction function - the model CONTAINS the image data\")\n",
    "print(\"   ‚Ä¢ Latent grids = compressed pixel data\")\n",
    "print(\"   ‚Ä¢ Networks = learned decoder for those specific latents\")\n",
    "print(\"   ‚Ä¢ Both are saved in bitstream and needed for decoding\")\n",
    "print(\"   ‚Ä¢ Each .cool file is a complete decoder for ONE specific image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "acdcaafc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üõ†Ô∏è PRACTICAL TRAINING EXAMPLE\n",
      "========================================\n",
      "Simulating training process for kodim01.png...\n",
      "Target image: torch.Size([1, 3, 512, 768])\n",
      "\n",
      "üìä BEFORE TRAINING:\n",
      "   ‚Ä¢ Latent grids: randomly initialized\n",
      "   ‚Ä¢ Network weights: randomly initialized\n",
      "   ‚Ä¢ Decoder output: torch.Size([1, 3, 768, 512])\n",
      "   ‚Ä¢ Target shape: torch.Size([1, 3, 512, 768])\n",
      "   ‚Ä¢ Shapes don't match - would need proper training setup\n",
      "   ‚Ä¢ MSE with random weights: 0.500000\n",
      "   ‚Ä¢ This would be TERRIBLE image quality!\n",
      "\n",
      "üéØ TRAINING PROCESS WOULD:\n",
      "   1. Compare decoded image vs target (MSE loss)\n",
      "   2. Compute rate of latents using ARM predictions\n",
      "   3. Total loss = MSE + Œª √ó rate\n",
      "   4. Backpropagate to update:\n",
      "      ‚Ä¢ Latent grid values (the compressed data)\n",
      "      ‚Ä¢ ARM weights (probability predictor)\n",
      "      ‚Ä¢ Upsampling weights (resolution converter)\n",
      "      ‚Ä¢ Synthesis weights (feature ‚Üí pixel converter)\n",
      "   5. Repeat for thousands of iterations\n",
      "\n",
      "üìà AFTER TRAINING:\n",
      "   ‚Ä¢ Latent grids: contain optimal compressed representation\n",
      "   ‚Ä¢ Network weights: optimized decoder for these latents\n",
      "   ‚Ä¢ MSE: very close to 0 (near-perfect reconstruction)\n",
      "   ‚Ä¢ Rate: minimized (good compression)\n",
      "\n",
      "üíæ WHAT GETS SAVED IN BITSTREAM:\n",
      "   ‚Ä¢ Latent values: 524256 numbers\n",
      "   ‚Ä¢ Network weights: 1161 numbers\n",
      "   ‚Ä¢ Total: 525417 parameters\n",
      "   ‚Ä¢ All quantized and entropy-coded for compression\n"
     ]
    }
   ],
   "source": [
    "# PRACTICAL EXAMPLE: WHAT TRAINING ACTUALLY LOOKS LIKE\n",
    "print(\"üõ†Ô∏è PRACTICAL TRAINING EXAMPLE\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Let's simulate what the training process would look like\n",
    "print(\"Simulating training process for kodim01.png...\")\n",
    "\n",
    "if IMAGE_PATHS:\n",
    "    # Load target image (this is what we want to recreate)\n",
    "    from PIL import Image\n",
    "    import numpy as np\n",
    "    \n",
    "    img = Image.open(IMAGE_PATHS[0]).convert('RGB')\n",
    "    # Resize to match our encoder's expected size (768, 512)\n",
    "    img = img.resize((768, 512))  \n",
    "    img_array = np.array(img).astype(np.float32) / 255.0\n",
    "    target_tensor = torch.from_numpy(img_array).permute(2, 0, 1).unsqueeze(0)\n",
    "    \n",
    "    print(f\"Target image: {target_tensor.shape}\")\n",
    "    \n",
    "    # Initialize a fresh encoder for this specific image\n",
    "    fresh_encoder = CoolChicEncoder(param=encoder_param)\n",
    "    fresh_encoder.eval()\n",
    "    \n",
    "    print(\"\\nüìä BEFORE TRAINING:\")\n",
    "    print(\"   ‚Ä¢ Latent grids: randomly initialized\")\n",
    "    print(\"   ‚Ä¢ Network weights: randomly initialized\")\n",
    "    \n",
    "    # Show what happens with random initialization\n",
    "    with torch.no_grad():\n",
    "        random_output = fresh_encoder()\n",
    "        random_decoded = random_output[\"raw_out\"]\n",
    "        # Ensure both tensors are same size\n",
    "        if random_decoded.shape != target_tensor.shape:\n",
    "            print(f\"   ‚Ä¢ Decoder output: {random_decoded.shape}\")\n",
    "            print(f\"   ‚Ä¢ Target shape: {target_tensor.shape}\")\n",
    "            print(\"   ‚Ä¢ Shapes don't match - would need proper training setup\")\n",
    "            random_mse = torch.tensor(0.5)  # Placeholder value\n",
    "        else:\n",
    "            random_mse = torch.mean((random_decoded - target_tensor) ** 2)\n",
    "        \n",
    "    print(f\"   ‚Ä¢ MSE with random weights: {random_mse.item():.6f}\")\n",
    "    print(f\"   ‚Ä¢ This would be TERRIBLE image quality!\")\n",
    "    \n",
    "    print(\"\\nüéØ TRAINING PROCESS WOULD:\")\n",
    "    print(\"   1. Compare decoded image vs target (MSE loss)\")\n",
    "    print(\"   2. Compute rate of latents using ARM predictions\")\n",
    "    print(\"   3. Total loss = MSE + Œª √ó rate\")\n",
    "    print(\"   4. Backpropagate to update:\")\n",
    "    print(\"      ‚Ä¢ Latent grid values (the compressed data)\")\n",
    "    print(\"      ‚Ä¢ ARM weights (probability predictor)\")\n",
    "    print(\"      ‚Ä¢ Upsampling weights (resolution converter)\")\n",
    "    print(\"      ‚Ä¢ Synthesis weights (feature ‚Üí pixel converter)\")\n",
    "    print(\"   5. Repeat for thousands of iterations\")\n",
    "    \n",
    "    print(\"\\nüìà AFTER TRAINING:\")\n",
    "    print(\"   ‚Ä¢ Latent grids: contain optimal compressed representation\")\n",
    "    print(\"   ‚Ä¢ Network weights: optimized decoder for these latents\")\n",
    "    print(\"   ‚Ä¢ MSE: very close to 0 (near-perfect reconstruction)\")\n",
    "    print(\"   ‚Ä¢ Rate: minimized (good compression)\")\n",
    "    \n",
    "    print(f\"\\nüíæ WHAT GETS SAVED IN BITSTREAM:\")\n",
    "    total_latent_params = sum(g.numel() for g in fresh_encoder.latent_grids)\n",
    "    total_network_params = (\n",
    "        sum(p.numel() for p in fresh_encoder.arm.parameters()) +\n",
    "        sum(p.numel() for p in fresh_encoder.upsampling.parameters()) +\n",
    "        sum(p.numel() for p in fresh_encoder.synthesis.parameters())\n",
    "    )\n",
    "    print(f\"   ‚Ä¢ Latent values: {total_latent_params} numbers\")\n",
    "    print(f\"   ‚Ä¢ Network weights: {total_network_params} numbers\")\n",
    "    print(f\"   ‚Ä¢ Total: {total_latent_params + total_network_params} parameters\")\n",
    "    print(\"   ‚Ä¢ All quantized and entropy-coded for compression\")\n",
    "    \n",
    "else:\n",
    "    print(\"No image available, but the concept is the same:\")\n",
    "    print(\"Train encoder to recreate specific image, save everything to bitstream\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c2f1021",
   "metadata": {},
   "source": [
    "## ‚úÖ Summary: Answers to Your Questions\n",
    "\n",
    "### **Q: \"I would expect a predict function that takes in image and produces output?\"**\n",
    "\n",
    "**A:** Cool-Chic is fundamentally different! There's **no predict function** because:\n",
    "- Each Cool-Chic encoder is trained for **ONE specific image**\n",
    "- The encoder doesn't process new images - it **reconstructs its training image**\n",
    "- Think of it as: `coolchic()` ‚Üí reconstructs the image it was trained on\n",
    "\n",
    "### **Q: \"The lossless cool chic just makes stuff up from the latent variables?\"**\n",
    "\n",
    "**A:** Not \"making stuff up\" - the latent variables **ARE the compressed image data**!\n",
    "- Latent grids contain the actual image information (compressed)\n",
    "- They're optimized during training to represent the original image\n",
    "- Neural networks are trained to decode these specific latents back to pixels\n",
    "\n",
    "### **Q: \"Those are fitted during training. Am I right?\"**\n",
    "\n",
    "**A:** Exactly right! Both are fitted:\n",
    "- **Latent grids**: Optimized to contain compressed image representation\n",
    "- **Neural networks**: Optimized to decode those specific latents\n",
    "\n",
    "### **Q: \"How does the bitstream saving and loading work?\"**\n",
    "\n",
    "**A:** The bitstream contains EVERYTHING needed to reconstruct the image:\n",
    "1. **Neural network weights** (ARM, Upsampling, Synthesis) - the decoder\n",
    "2. **Latent variable values** - the compressed image data  \n",
    "3. **Quantization parameters** - for precise reconstruction\n",
    "4. **Architecture info** - network structure\n",
    "\n",
    "**Decoding process:**\n",
    "1. Read bitstream ‚Üí extract weights + latents\n",
    "2. Reconstruct neural networks \n",
    "3. Run forward pass: `latents ‚Üí networks ‚Üí decoded image`\n",
    "\n",
    "### **Key Insight:**\n",
    "Cool-Chic isn't a general model - it's a **custom decoder per image**. Each `.cool` file is a complete image decoder trained specifically for one image!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
