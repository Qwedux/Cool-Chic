{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a0b81455",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using model: 2025_11_22__16_44_29__trained_coolchic_kodak_kodim01_img_rate_3.2631609439849854.pth\n",
      "Converting image to YCoCg color space\n",
      "Best loss for module arm: Loss: 3.265453577041626, Rate NN: 0.0022328693885356188, Rate Latent: 0.04100216552615166, Rate Img: 3.2222185134887695\n",
      "Best loss for module synthesis: Loss: 3.2731027603149414, Rate NN: 0.009442646987736225, Rate Latent: 0.04100216552615166, Rate Img: 3.2226579189300537\n",
      "Best loss for module upsampling: Loss: 3.273566484451294, Rate NN: 0.009930928237736225, Rate Latent: 0.04100216552615166, Rate Img: 3.2226333618164062\n",
      "\n",
      "Time quantize_model():  6.0 seconds\n",
      "\n",
      "Rate per module: {'arm': {'bias': tensor(159., device='cuda:0'), 'weight': tensor(2475., device='cuda:0')}, 'upsampling': {'bias': tensor(12., device='cuda:0'), 'weight': tensor(564., device='cuda:0')}, 'synthesis': {'bias': tensor(600., device='cuda:0'), 'weight': tensor(7905., device='cuda:0')}},\n",
      " Final results after quantization: Loss: 3.297492265701294, Rate NN: 0.03385670855641365, Rate Latent: 0.04100216552615166, Rate Img: 3.2226333618164062\n",
      "Using model: 2025_11_22__16_49_46__trained_coolchic_kodak_kodim02_img_rate_2.891050338745117.pth\n",
      "Converting image to YCoCg color space\n",
      "Best loss for module arm: Loss: 2.893411874771118, Rate NN: 0.0020531548652797937, Rate Latent: 0.060510337352752686, Rate Img: 2.830848217010498\n",
      "Best loss for module synthesis: Loss: 2.900071620941162, Rate NN: 0.007267422042787075, Rate Latent: 0.060510337352752686, Rate Img: 2.832293748855591\n",
      "Best loss for module upsampling: Loss: 2.900292158126831, Rate NN: 0.0076268515549600124, Rate Latent: 0.060510337352752686, Rate Img: 2.8321549892425537\n",
      "\n",
      "Time quantize_model():  5.6 seconds\n",
      "\n",
      "Rate per module: {'arm': {'bias': tensor(185., device='cuda:0'), 'weight': tensor(2237., device='cuda:0')}, 'upsampling': {'bias': tensor(12., device='cuda:0'), 'weight': tensor(412., device='cuda:0')}, 'synthesis': {'bias': tensor(606., device='cuda:0'), 'weight': tensor(5545., device='cuda:0')}},\n",
      " Final results after quantization: Loss: 2.924217939376831, Rate NN: 0.03155263140797615, Rate Latent: 0.060510337352752686, Rate Img: 2.8321549892425537\n",
      "Using model: 2025_11_22__16_40_11__trained_coolchic_kodak_kodim03_img_rate_2.5163798332214355.pth\n",
      "Converting image to YCoCg color space\n",
      "Best loss for module arm: Loss: 2.5185494422912598, Rate NN: 0.0019955106545239687, Rate Latent: 0.025035932660102844, Rate Img: 2.491518020629883\n",
      "Best loss for module synthesis: Loss: 2.52559232711792, Rate NN: 0.0088653564453125, Rate Latent: 0.025035932660102844, Rate Img: 2.4916911125183105\n",
      "Best loss for module upsampling: Loss: 2.5259616374969482, Rate NN: 0.0092146135866642, Rate Latent: 0.025035932660102844, Rate Img: 2.491711139678955\n",
      "\n",
      "Time quantize_model():  5.4 seconds\n",
      "\n",
      "Rate per module: {'arm': {'bias': tensor(128., device='cuda:0'), 'weight': tensor(2226., device='cuda:0')}, 'upsampling': {'bias': tensor(12., device='cuda:0'), 'weight': tensor(400., device='cuda:0')}, 'synthesis': {'bias': tensor(556., device='cuda:0'), 'weight': tensor(7548., device='cuda:0')}},\n",
      " Final results after quantization: Loss: 2.5498874187469482, Rate NN: 0.0331403948366642, Rate Latent: 0.025035932660102844, Rate Img: 2.491711139678955\n",
      "Using model: 2025_11_22__16_36_55__trained_coolchic_kodak_kodim04_img_rate_2.940075635910034.pth\n",
      "Converting image to YCoCg color space\n",
      "Best loss for module arm: Loss: 2.942410707473755, Rate NN: 0.0023447673302143812, Rate Latent: 0.029971875250339508, Rate Img: 2.9100940227508545\n",
      "Best loss for module synthesis: Loss: 2.9488775730133057, Rate NN: 0.00843132846057415, Rate Latent: 0.029971875250339508, Rate Img: 2.9104743003845215\n",
      "Best loss for module upsampling: Loss: 2.94929575920105, Rate NN: 0.00878228060901165, Rate Latent: 0.029971875250339508, Rate Img: 2.910541534423828\n",
      "\n",
      "Time quantize_model():  5.7 seconds\n",
      "\n",
      "Rate per module: {'arm': {'bias': tensor(197., device='cuda:0'), 'weight': tensor(2569., device='cuda:0')}, 'upsampling': {'bias': tensor(12., device='cuda:0'), 'weight': tensor(402., device='cuda:0')}, 'synthesis': {'bias': tensor(587., device='cuda:0'), 'weight': tensor(6593., device='cuda:0')}},\n",
      " Final results after quantization: Loss: 2.97322154045105, Rate NN: 0.0327080637216568, Rate Latent: 0.029971875250339508, Rate Img: 2.910541534423828\n",
      "Using model: 2025_11_22__16_22_12__trained_coolchic_kodak_kodim05_img_rate_3.462815284729004.pth\n",
      "Converting image to YCoCg color space\n",
      "Best loss for module arm: Loss: 3.46539306640625, Rate NN: 0.0020997789688408375, Rate Latent: 0.06432169675827026, Rate Img: 3.3989715576171875\n",
      "Best loss for module synthesis: Loss: 3.4720520973205566, Rate NN: 0.0081770159304142, Rate Latent: 0.06432169675827026, Rate Img: 3.3995532989501953\n",
      "Best loss for module upsampling: Loss: 3.472504138946533, Rate NN: 0.00856696255505085, Rate Latent: 0.06432169675827026, Rate Img: 3.399615526199341\n",
      "\n",
      "Time quantize_model():  5.4 seconds\n",
      "\n",
      "Rate per module: {'arm': {'bias': tensor(130., device='cuda:0'), 'weight': tensor(2347., device='cuda:0')}, 'upsampling': {'bias': tensor(12., device='cuda:0'), 'weight': tensor(448., device='cuda:0')}, 'synthesis': {'bias': tensor(651., device='cuda:0'), 'weight': tensor(6518., device='cuda:0')}},\n",
      " Final results after quantization: Loss: 3.496429920196533, Rate NN: 0.032492745667696, Rate Latent: 0.06432169675827026, Rate Img: 3.399615526199341\n",
      "Using model: 2025_11_22__16_20_48__trained_coolchic_kodak_kodim06_img_rate_3.052344799041748.pth\n",
      "Converting image to YCoCg color space\n",
      "Best loss for module arm: Loss: 3.056852102279663, Rate NN: 0.0023710462264716625, Rate Latent: 0.08133690804243088, Rate Img: 2.973144054412842\n",
      "Best loss for module synthesis: Loss: 3.0640900135040283, Rate NN: 0.008575439453125, Rate Latent: 0.08133690804243088, Rate Img: 2.974177598953247\n",
      "Best loss for module upsampling: Loss: 3.064633846282959, Rate NN: 0.009073893539607525, Rate Latent: 0.08133690804243088, Rate Img: 2.9742228984832764\n",
      "\n",
      "Time quantize_model():  5.5 seconds\n",
      "\n",
      "Rate per module: {'arm': {'bias': tensor(130., device='cuda:0'), 'weight': tensor(2667., device='cuda:0')}, 'upsampling': {'bias': tensor(12., device='cuda:0'), 'weight': tensor(576., device='cuda:0')}, 'synthesis': {'bias': tensor(620., device='cuda:0'), 'weight': tensor(6699., device='cuda:0')}},\n",
      " Final results after quantization: Loss: 3.088559627532959, Rate NN: 0.0329996757209301, Rate Latent: 0.08133690804243088, Rate Img: 2.9742228984832764\n",
      "Using model: 2025_11_22__16_21_23__trained_coolchic_kodak_kodim07_img_rate_2.7262864112854004.pth\n",
      "Converting image to YCoCg color space\n",
      "Best loss for module arm: Loss: 2.7289376258850098, Rate NN: 0.0023100110702216625, Rate Latent: 0.053428806364536285, Rate Img: 2.673198699951172\n",
      "Best loss for module synthesis: Loss: 2.7354960441589355, Rate NN: 0.008778889663517475, Rate Latent: 0.053428806364536285, Rate Img: 2.673288345336914\n",
      "Best loss for module upsampling: Loss: 2.7359259128570557, Rate NN: 0.00922478549182415, Rate Latent: 0.053428806364536285, Rate Img: 2.673272132873535\n",
      "\n",
      "Time quantize_model():  5.4 seconds\n",
      "\n",
      "Rate per module: {'arm': {'bias': tensor(114., device='cuda:0'), 'weight': tensor(2611., device='cuda:0')}, 'upsampling': {'bias': tensor(12., device='cuda:0'), 'weight': tensor(514., device='cuda:0')}, 'synthesis': {'bias': tensor(622., device='cuda:0'), 'weight': tensor(7009., device='cuda:0')}},\n",
      " Final results after quantization: Loss: 2.7598516941070557, Rate NN: 0.0331505686044693, Rate Latent: 0.053428806364536285, Rate Img: 2.673272132873535\n",
      "Using model: 2025_11_22__16_21_11__trained_coolchic_kodak_kodim08_img_rate_3.5159599781036377.pth\n",
      "Converting image to YCoCg color space\n",
      "Best loss for module arm: Loss: 3.518383502960205, Rate NN: 0.0020896063651889563, Rate Latent: 0.07059849798679352, Rate Img: 3.445695400238037\n",
      "Best loss for module synthesis: Loss: 3.5252749919891357, Rate NN: 0.008419460617005825, Rate Latent: 0.07059849798679352, Rate Img: 3.4462568759918213\n",
      "Best loss for module upsampling: Loss: 3.525735378265381, Rate NN: 0.0088636614382267, Rate Latent: 0.07059849798679352, Rate Img: 3.4462730884552\n",
      "\n",
      "Time quantize_model():  5.3 seconds\n",
      "\n",
      "Rate per module: {'arm': {'bias': tensor(136., device='cuda:0'), 'weight': tensor(2329., device='cuda:0')}, 'upsampling': {'bias': tensor(12., device='cuda:0'), 'weight': tensor(512., device='cuda:0')}, 'synthesis': {'bias': tensor(655., device='cuda:0'), 'weight': tensor(6812., device='cuda:0')}},\n",
      " Final results after quantization: Loss: 3.549661159515381, Rate NN: 0.0327894426882267, Rate Latent: 0.07059849798679352, Rate Img: 3.4462730884552\n",
      "Using model: 2025_11_22__16_23_30__trained_coolchic_kodak_kodim09_img_rate_2.856290817260742.pth\n",
      "Converting image to YCoCg color space\n",
      "Best loss for module arm: Loss: 2.8566324710845947, Rate NN: 0.00034162733936682343, Rate Latent: 0.007486979477107525, Rate Img: 2.848803758621216\n",
      "Best loss for module synthesis: Loss: 2.8586337566375732, Rate NN: 0.002227783203125, Rate Latent: 0.007486979477107525, Rate Img: 2.848918914794922\n",
      "Best loss for module upsampling: Loss: 2.858717679977417, Rate NN: 0.00231170654296875, Rate Latent: 0.007486979477107525, Rate Img: 2.848918914794922\n",
      "\n",
      "Time quantize_model():  6.4 seconds\n",
      "\n",
      "Rate per module: {'arm': {'bias': tensor(32., device='cuda:0'), 'weight': tensor(371., device='cuda:0')}, 'upsampling': {'bias': tensor(12., device='cuda:0'), 'weight': tensor(87., device='cuda:0')}, 'synthesis': {'bias': tensor(611., device='cuda:0'), 'weight': tensor(1614., device='cuda:0')}},\n",
      " Final results after quantization: Loss: 2.882643461227417, Rate NN: 0.02623748779296875, Rate Latent: 0.007486979477107525, Rate Img: 2.848918914794922\n",
      "Using model: 2025_11_22__16_21_25__trained_coolchic_kodak_kodim10_img_rate_2.9068071842193604.pth\n",
      "Converting image to YCoCg color space\n",
      "Best loss for module arm: Loss: 2.9073896408081055, Rate NN: 0.0005823771352879703, Rate Latent: 0.001681857742369175, Rate Img: 2.905125379562378\n",
      "Best loss for module synthesis: Loss: 2.9099671840667725, Rate NN: 0.0031500922050327063, Rate Latent: 0.001681857742369175, Rate Img: 2.9051353931427\n",
      "Best loss for module upsampling: Loss: 2.9100258350372314, Rate NN: 0.0032085843849927187, Rate Latent: 0.001681857742369175, Rate Img: 2.9051353931427\n",
      "\n",
      "Time quantize_model():  5.6 seconds\n",
      "\n",
      "Rate per module: {'arm': {'bias': tensor(72., device='cuda:0'), 'weight': tensor(615., device='cuda:0')}, 'upsampling': {'bias': tensor(12., device='cuda:0'), 'weight': tensor(57., device='cuda:0')}, 'synthesis': {'bias': tensor(703., device='cuda:0'), 'weight': tensor(2326., device='cuda:0')}},\n",
      " Final results after quantization: Loss: 2.9339516162872314, Rate NN: 0.02713436633348465, Rate Latent: 0.001681857742369175, Rate Img: 2.9051353931427\n",
      "Using model: 2025_11_22__16_23_33__trained_coolchic_kodak_kodim11_img_rate_2.9669723510742188.pth\n",
      "Converting image to YCoCg color space\n",
      "Best loss for module arm: Loss: 2.9692862033843994, Rate NN: 0.0017267862567678094, Rate Latent: 0.023256998509168625, Rate Img: 2.9443023204803467\n",
      "Best loss for module synthesis: Loss: 2.975954055786133, Rate NN: 0.007831997238099575, Rate Latent: 0.023256998509168625, Rate Img: 2.9448649883270264\n",
      "Best loss for module upsampling: Loss: 2.976323366165161, Rate NN: 0.0082380510866642, Rate Latent: 0.023256998509168625, Rate Img: 2.9448282718658447\n",
      "\n",
      "Time quantize_model():  5.8 seconds\n",
      "\n",
      "Rate per module: {'arm': {'bias': tensor(192., device='cuda:0'), 'weight': tensor(1845., device='cuda:0')}, 'upsampling': {'bias': tensor(12., device='cuda:0'), 'weight': tensor(467., device='cuda:0')}, 'synthesis': {'bias': tensor(558., device='cuda:0'), 'weight': tensor(6644., device='cuda:0')}},\n",
      " Final results after quantization: Loss: 3.000249147415161, Rate NN: 0.0321638323366642, Rate Latent: 0.023256998509168625, Rate Img: 2.9448282718658447\n",
      "Using model: 2025_11_22__16_21_07__trained_coolchic_kodak_kodim12_img_rate_2.796745777130127.pth\n",
      "Converting image to YCoCg color space\n",
      "Best loss for module arm: Loss: 2.799194812774658, Rate NN: 0.0023566351737827063, Rate Latent: 0.019053708761930466, Rate Img: 2.777784585952759\n",
      "Best loss for module synthesis: Loss: 2.806382417678833, Rate NN: 0.00870513916015625, Rate Latent: 0.019053708761930466, Rate Img: 2.778623580932617\n",
      "Best loss for module upsampling: Loss: 2.806746244430542, Rate NN: 0.0090933907777071, Rate Latent: 0.019053708761930466, Rate Img: 2.778599262237549\n",
      "\n",
      "Time quantize_model():  5.8 seconds\n",
      "\n",
      "Rate per module: {'arm': {'bias': tensor(159., device='cuda:0'), 'weight': tensor(2621., device='cuda:0')}, 'upsampling': {'bias': tensor(12., device='cuda:0'), 'weight': tensor(446., device='cuda:0')}, 'synthesis': {'bias': tensor(515., device='cuda:0'), 'weight': tensor(6974., device='cuda:0')}},\n",
      " Final results after quantization: Loss: 2.830672025680542, Rate NN: 0.03301917389035225, Rate Latent: 0.019053708761930466, Rate Img: 2.778599262237549\n",
      "Using model: 2025_11_22__16_20_12__trained_coolchic_kodak_kodim13_img_rate_3.800956964492798.pth\n",
      "Converting image to YCoCg color space\n",
      "Best loss for module arm: Loss: 3.803234577178955, Rate NN: 0.0021608141250908375, Rate Latent: 0.03161245584487915, Rate Img: 3.7694613933563232\n",
      "Best loss for module synthesis: Loss: 3.809666633605957, Rate NN: 0.007149590644985437, Rate Latent: 0.03161245584487915, Rate Img: 3.770904541015625\n",
      "Best loss for module upsampling: Loss: 3.8100509643554688, Rate NN: 0.0075531005859375, Rate Latent: 0.03161245584487915, Rate Img: 3.770885467529297\n",
      "\n",
      "Time quantize_model():  5.7 seconds\n",
      "\n",
      "Rate per module: {'arm': {'bias': tensor(175., device='cuda:0'), 'weight': tensor(2374., device='cuda:0')}, 'upsampling': {'bias': tensor(12., device='cuda:0'), 'weight': tensor(464., device='cuda:0')}, 'synthesis': {'bias': tensor(540., device='cuda:0'), 'weight': tensor(5345., device='cuda:0')}},\n",
      " Final results after quantization: Loss: 3.8339767456054688, Rate NN: 0.0314788818359375, Rate Latent: 0.03161245584487915, Rate Img: 3.770885467529297\n",
      "Using model: 2025_11_22__16_28_13__trained_coolchic_kodak_kodim14_img_rate_3.209195137023926.pth\n",
      "Converting image to YCoCg color space\n",
      "Best loss for module arm: Loss: 3.211789608001709, Rate NN: 0.0020573933143168688, Rate Latent: 0.050470709800720215, Rate Img: 3.159261465072632\n",
      "Best loss for module synthesis: Loss: 3.2183542251586914, Rate NN: 0.00813886895775795, Rate Latent: 0.050470709800720215, Rate Img: 3.1597445011138916\n",
      "Best loss for module upsampling: Loss: 3.218827724456787, Rate NN: 0.00859832763671875, Rate Latent: 0.050470709800720215, Rate Img: 3.1597588062286377\n",
      "\n",
      "Time quantize_model():  6.1 seconds\n",
      "\n",
      "Rate per module: {'arm': {'bias': tensor(125., device='cuda:0'), 'weight': tensor(2302., device='cuda:0')}, 'upsampling': {'bias': tensor(12., device='cuda:0'), 'weight': tensor(530., device='cuda:0')}, 'synthesis': {'bias': tensor(665., device='cuda:0'), 'weight': tensor(6509., device='cuda:0')}},\n",
      " Final results after quantization: Loss: 3.242753505706787, Rate NN: 0.03252410888671875, Rate Latent: 0.050470709800720215, Rate Img: 3.1597588062286377\n",
      "Using model: 2025_11_22__20_19_50__trained_coolchic_kodak_kodim15_img_rate_2.7757809162139893.pth\n",
      "Converting image to YCoCg color space\n",
      "Best loss for module arm: Loss: 2.7781102657318115, Rate NN: 0.0023125542793422937, Rate Latent: 0.02365299127995968, Rate Img: 2.7521445751190186\n",
      "Best loss for module synthesis: Loss: 2.784503221511841, Rate NN: 0.008526272140443325, Rate Latent: 0.02365299127995968, Rate Img: 2.752323865890503\n",
      "Best loss for module upsampling: Loss: 2.784947395324707, Rate NN: 0.008945041336119175, Rate Latent: 0.02365299127995968, Rate Img: 2.752349376678467\n",
      "\n",
      "Time quantize_model():  5.8 seconds\n",
      "\n",
      "Rate per module: {'arm': {'bias': tensor(181., device='cuda:0'), 'weight': tensor(2547., device='cuda:0')}, 'upsampling': {'bias': tensor(12., device='cuda:0'), 'weight': tensor(482., device='cuda:0')}, 'synthesis': {'bias': tensor(654., device='cuda:0'), 'weight': tensor(6676., device='cuda:0')}},\n",
      " Final results after quantization: Loss: 2.808873176574707, Rate NN: 0.0328708216547966, Rate Latent: 0.02365299127995968, Rate Img: 2.752349376678467\n",
      "Using model: 2025_11_22__20_21_04__trained_coolchic_kodak_kodim16_img_rate_2.7645039558410645.pth\n",
      "Converting image to YCoCg color space\n",
      "Best loss for module arm: Loss: 2.7666139602661133, Rate NN: 0.0021099515724927187, Rate Latent: 0.02711511217057705, Rate Img: 2.737388849258423\n",
      "Best loss for module synthesis: Loss: 2.772815227508545, Rate NN: 0.007822672836482525, Rate Latent: 0.02711511217057705, Rate Img: 2.737877368927002\n",
      "Best loss for module upsampling: Loss: 2.7732105255126953, Rate NN: 0.00818464532494545, Rate Latent: 0.02711511217057705, Rate Img: 2.737910747528076\n",
      "\n",
      "Time quantize_model():  6.6 seconds\n",
      "\n",
      "Rate per module: {'arm': {'bias': tensor(185., device='cuda:0'), 'weight': tensor(2304., device='cuda:0')}, 'upsampling': {'bias': tensor(12., device='cuda:0'), 'weight': tensor(415., device='cuda:0')}, 'synthesis': {'bias': tensor(641., device='cuda:0'), 'weight': tensor(6098., device='cuda:0')}},\n",
      " Final results after quantization: Loss: 2.7971363067626953, Rate NN: 0.03211042657494545, Rate Latent: 0.02711511217057705, Rate Img: 2.737910747528076\n",
      "Using model: 2025_11_22__20_21_35__trained_coolchic_kodak_kodim17_img_rate_2.8476359844207764.pth\n",
      "Converting image to YCoCg color space\n",
      "Best loss for module arm: Loss: 2.8497414588928223, Rate NN: 0.0018564859637990594, Rate Latent: 0.021511396393179893, Rate Img: 2.82637357711792\n",
      "Best loss for module synthesis: Loss: 2.8563342094421387, Rate NN: 0.008462694473564625, Rate Latent: 0.021511396393179893, Rate Img: 2.8263602256774902\n",
      "Best loss for module upsampling: Loss: 2.8567333221435547, Rate NN: 0.008874681778252125, Rate Latent: 0.021511396393179893, Rate Img: 2.8263473510742188\n",
      "\n",
      "Time quantize_model():  5.9 seconds\n",
      "\n",
      "Rate per module: {'arm': {'bias': tensor(86., device='cuda:0'), 'weight': tensor(2104., device='cuda:0')}, 'upsampling': {'bias': tensor(12., device='cuda:0'), 'weight': tensor(474., device='cuda:0')}, 'synthesis': {'bias': tensor(634., device='cuda:0'), 'weight': tensor(7159., device='cuda:0')}},\n",
      " Final results after quantization: Loss: 2.8806591033935547, Rate NN: 0.03280046209692955, Rate Latent: 0.021511396393179893, Rate Img: 2.8263473510742188\n",
      "Using model: 2025_11_22__20_20_12__trained_coolchic_kodak_kodim18_img_rate_3.4783613681793213.pth\n",
      "Converting image to YCoCg color space\n",
      "Best loss for module arm: Loss: 3.4807090759277344, Rate NN: 0.0021938749123364687, Rate Latent: 0.01983063481748104, Rate Img: 3.4586844444274902\n",
      "Best loss for module synthesis: Loss: 3.4862332344055176, Rate NN: 0.0068486533127725124, Rate Latent: 0.01983063481748104, Rate Img: 3.4595539569854736\n",
      "Best loss for module upsampling: Loss: 3.4866902828216553, Rate NN: 0.0073081124573946, Rate Latent: 0.01983063481748104, Rate Img: 3.4595515727996826\n",
      "\n",
      "Time quantize_model():  5.8 seconds\n",
      "\n",
      "Rate per module: {'arm': {'bias': tensor(189., device='cuda:0'), 'weight': tensor(2399., device='cuda:0')}, 'upsampling': {'bias': tensor(12., device='cuda:0'), 'weight': tensor(530., device='cuda:0')}, 'synthesis': {'bias': tensor(417., device='cuda:0'), 'weight': tensor(5074., device='cuda:0')}},\n",
      " Final results after quantization: Loss: 3.5106160640716553, Rate NN: 0.0312338937073946, Rate Latent: 0.01983063481748104, Rate Img: 3.4595515727996826\n",
      "Using model: 2025_11_22__20_22_29__trained_coolchic_kodak_kodim19_img_rate_3.081232786178589.pth\n",
      "Converting image to YCoCg color space\n",
      "Best loss for module arm: Loss: 3.08392596244812, Rate NN: 0.0023701984900981188, Rate Latent: 0.02038809284567833, Rate Img: 3.0611677169799805\n",
      "Best loss for module synthesis: Loss: 3.0903615951538086, Rate NN: 0.008396572433412075, Rate Latent: 0.02038809284567833, Rate Img: 3.0615768432617188\n",
      "Best loss for module upsampling: Loss: 3.0907881259918213, Rate NN: 0.008837382309138775, Rate Latent: 0.02038809284567833, Rate Img: 3.0615625381469727\n",
      "\n",
      "Time quantize_model():  5.6 seconds\n",
      "\n",
      "Rate per module: {'arm': {'bias': tensor(165., device='cuda:0'), 'weight': tensor(2631., device='cuda:0')}, 'upsampling': {'bias': tensor(12., device='cuda:0'), 'weight': tensor(508., device='cuda:0')}, 'synthesis': {'bias': tensor(643., device='cuda:0'), 'weight': tensor(6466., device='cuda:0')}},\n",
      " Final results after quantization: Loss: 3.1147139072418213, Rate NN: 0.03276316449046135, Rate Latent: 0.02038809284567833, Rate Img: 3.0615625381469727\n",
      "Using model: 2025_11_22__20_22_18__trained_coolchic_kodak_kodim20_img_rate_2.5551726818084717.pth\n",
      "Converting image to YCoCg color space\n",
      "Best loss for module arm: Loss: 2.5574605464935303, Rate NN: 0.0021226671524345875, Rate Latent: 0.04110421612858772, Rate Img: 2.5142335891723633\n",
      "Best loss for module synthesis: Loss: 2.5645415782928467, Rate NN: 0.008320278488099575, Rate Latent: 0.04110421612858772, Rate Img: 2.5151169300079346\n",
      "Best loss for module upsampling: Loss: 2.564971446990967, Rate NN: 0.008754306472837925, Rate Latent: 0.04110421612858772, Rate Img: 2.51511287689209\n",
      "\n",
      "Time quantize_model():  5.8 seconds\n",
      "\n",
      "Rate per module: {'arm': {'bias': tensor(208., device='cuda:0'), 'weight': tensor(2296., device='cuda:0')}, 'upsampling': {'bias': tensor(12., device='cuda:0'), 'weight': tensor(500., device='cuda:0')}, 'synthesis': {'bias': tensor(655., device='cuda:0'), 'weight': tensor(6656., device='cuda:0')}},\n",
      " Final results after quantization: Loss: 2.588897228240967, Rate NN: 0.03268008679151535, Rate Latent: 0.04110421612858772, Rate Img: 2.51511287689209\n",
      "Using model: 2025_11_22__20_24_07__trained_coolchic_kodak_kodim21_img_rate_3.1340839862823486.pth\n",
      "Converting image to YCoCg color space\n",
      "Best loss for module arm: Loss: 3.1362433433532715, Rate NN: 0.0018573337001726031, Rate Latent: 0.03584197163581848, Rate Img: 3.098544120788574\n",
      "Best loss for module synthesis: Loss: 3.1439597606658936, Rate NN: 0.0086212158203125, Rate Latent: 0.03584197163581848, Rate Img: 3.099496603012085\n",
      "Best loss for module upsampling: Loss: 3.1443846225738525, Rate NN: 0.00897979736328125, Rate Latent: 0.03584197163581848, Rate Img: 3.099562883377075\n",
      "\n",
      "Time quantize_model():  6.0 seconds\n",
      "\n",
      "Rate per module: {'arm': {'bias': tensor(175., device='cuda:0'), 'weight': tensor(2016., device='cuda:0')}, 'upsampling': {'bias': tensor(12., device='cuda:0'), 'weight': tensor(411., device='cuda:0')}, 'synthesis': {'bias': tensor(621., device='cuda:0'), 'weight': tensor(7358., device='cuda:0')}},\n",
      " Final results after quantization: Loss: 3.1683104038238525, Rate NN: 0.03290557861328125, Rate Latent: 0.03584197163581848, Rate Img: 3.099562883377075\n",
      "Using model: 2025_11_22__20_26_18__trained_coolchic_kodak_kodim22_img_rate_3.267078399658203.pth\n",
      "Converting image to YCoCg color space\n",
      "Best loss for module arm: Loss: 3.2692387104034424, Rate NN: 0.0018547906074672937, Rate Latent: 0.021479999646544456, Rate Img: 3.245903730392456\n",
      "Best loss for module synthesis: Loss: 3.2762272357940674, Rate NN: 0.008676317520439625, Rate Latent: 0.021479999646544456, Rate Img: 3.2460708618164062\n",
      "Best loss for module upsampling: Loss: 3.276674747467041, Rate NN: 0.009080675430595875, Rate Latent: 0.021479999646544456, Rate Img: 3.2461140155792236\n",
      "\n",
      "Time quantize_model():  5.8 seconds\n",
      "\n",
      "Rate per module: {'arm': {'bias': tensor(156., device='cuda:0'), 'weight': tensor(2032., device='cuda:0')}, 'upsampling': {'bias': tensor(12., device='cuda:0'), 'weight': tensor(465., device='cuda:0')}, 'synthesis': {'bias': tensor(632., device='cuda:0'), 'weight': tensor(7415., device='cuda:0')}},\n",
      " Final results after quantization: Loss: 3.300600528717041, Rate NN: 0.0330064557492733, Rate Latent: 0.021479999646544456, Rate Img: 3.2461140155792236\n",
      "Using model: 2025_11_22__20_25_11__trained_coolchic_kodak_kodim23_img_rate_2.711838722229004.pth\n",
      "Converting image to YCoCg color space\n",
      "Best loss for module arm: Loss: 2.7140042781829834, Rate NN: 0.0021192762069404125, Rate Latent: 0.031785547733306885, Rate Img: 2.6800994873046875\n",
      "Best loss for module synthesis: Loss: 2.720679521560669, Rate NN: 0.008594089187681675, Rate Latent: 0.031785547733306885, Rate Img: 2.680299997329712\n",
      "Best loss for module upsampling: Loss: 2.721083641052246, Rate NN: 0.0089857317507267, Rate Latent: 0.031785547733306885, Rate Img: 2.680312395095825\n",
      "\n",
      "Time quantize_model():  6.0 seconds\n",
      "\n",
      "Rate per module: {'arm': {'bias': tensor(185., device='cuda:0'), 'weight': tensor(2315., device='cuda:0')}, 'upsampling': {'bias': tensor(12., device='cuda:0'), 'weight': tensor(450., device='cuda:0')}, 'synthesis': {'bias': tensor(621., device='cuda:0'), 'weight': tensor(7017., device='cuda:0')}},\n",
      " Final results after quantization: Loss: 2.745009422302246, Rate NN: 0.0329115130007267, Rate Latent: 0.031785547733306885, Rate Img: 2.680312395095825\n",
      "Using model: 2025_11_22__20_34_48__trained_coolchic_kodak_kodim24_img_rate_3.193049430847168.pth\n",
      "Converting image to YCoCg color space\n",
      "Best loss for module arm: Loss: 3.1956288814544678, Rate NN: 0.0021540324669331312, Rate Latent: 0.03982299566268921, Rate Img: 3.153651714324951\n",
      "Best loss for module synthesis: Loss: 3.202401638031006, Rate NN: 0.0088339913636446, Rate Latent: 0.03982299566268921, Rate Img: 3.153744697570801\n",
      "Best loss for module upsampling: Loss: 3.2027978897094727, Rate NN: 0.00923919677734375, Rate Latent: 0.03982299566268921, Rate Img: 3.153735637664795\n",
      "\n",
      "Time quantize_model():  5.8 seconds\n",
      "\n",
      "Rate per module: {'arm': {'bias': tensor(139., device='cuda:0'), 'weight': tensor(2402., device='cuda:0')}, 'upsampling': {'bias': tensor(12., device='cuda:0'), 'weight': tensor(466., device='cuda:0')}, 'synthesis': {'bias': tensor(616., device='cuda:0'), 'weight': tensor(7264., device='cuda:0')}},\n",
      " Final results after quantization: Loss: 3.2267236709594727, Rate NN: 0.03316497802734375, Rate Latent: 0.03982299566268921, Rate Img: 3.153735637664795\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "\n",
    "if os.path.basename(os.getcwd()) == \"analysis\":\n",
    "    os.chdir(os.path.dirname(os.getcwd()))\n",
    "    sys.path.append(os.getcwd())\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from lossless.component.coolchic import CoolChicEncoder, CoolChicEncoderParameter\n",
    "from lossless.nnquant.quantizemodel import quantize_model\n",
    "from lossless.training.loss import loss_function\n",
    "from lossless.training.manager import ImageEncoderManager\n",
    "from lossless.util.config import args\n",
    "from lossless.util.image_loading import load_image_as_tensor\n",
    "from lossless.util.parsecli import (\n",
    "    change_n_out_synth,\n",
    "    get_coolchic_param_from_args,\n",
    "    get_manager_from_args,\n",
    ")\n",
    "\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "torch.set_float32_matmul_precision(\"high\")\n",
    "\n",
    "model_location_dir = \"../logs/full_runs/21_11_2025_YCoCg_with_fixed_colorregression/trained_models\"\n",
    "model_paths = os.listdir(model_location_dir)\n",
    "model_paths = sorted(model_paths, key=lambda x: int(x.split(\"_kodim\")[1].split(\"_\")[0]))\n",
    "\n",
    "table = []\n",
    "for img_index in range(len(model_paths)):\n",
    "    color_space = \"YCoCg\"\n",
    "    use_image_arm = True\n",
    "    print(f\"Using model: {model_paths[img_index]}\")\n",
    "\n",
    "    im_path = args[\"input\"][img_index]\n",
    "    im_tensor, c_bitdepths = load_image_as_tensor(im_path, device=\"cuda:0\", color_space=color_space)\n",
    "\n",
    "    # ==========================================================================================\n",
    "    # LOAD PRESETS, COOLCHIC PARAMETERS\n",
    "    # ==========================================================================================\n",
    "    image_encoder_manager = ImageEncoderManager(**get_manager_from_args(args))\n",
    "    encoder_param = CoolChicEncoderParameter(**get_coolchic_param_from_args(args, \"lossless\"))\n",
    "    encoder_param.set_image_size((im_tensor.shape[2], im_tensor.shape[3]))\n",
    "    encoder_param.layers_synthesis = change_n_out_synth(\n",
    "        encoder_param.layers_synthesis, args[\"output_dim_size\"]\n",
    "    )\n",
    "    encoder_param.use_image_arm = use_image_arm\n",
    "    coolchic = CoolChicEncoder(param=encoder_param)\n",
    "    coolchic.to_device(\"cuda:0\")\n",
    "    coolchic.load_state_dict(torch.load(os.path.join(model_location_dir, model_paths[img_index])))\n",
    "\n",
    "    # ==========================================================================================\n",
    "    # QUANTIZE AND EVALUATE\n",
    "    # ==========================================================================================\n",
    "    # technically we don't need quantization when working with uncompressed model\n",
    "    quantized_coolchic = CoolChicEncoder(param=encoder_param)\n",
    "    quantized_coolchic.to_device(\"cuda:0\")\n",
    "    quantized_coolchic.set_param(coolchic.get_param())\n",
    "    quantized_coolchic = quantize_model(\n",
    "        quantized_coolchic,\n",
    "        im_tensor,\n",
    "        image_encoder_manager,\n",
    "        None, # type:ignore\n",
    "        color_bitdepths=c_bitdepths,\n",
    "    )\n",
    "    rate_per_module, total_network_rate = quantized_coolchic.get_network_rate()\n",
    "    with torch.no_grad():\n",
    "        arm_params = list(quantized_coolchic.image_arm.parameters())\n",
    "        arm_params_bits = sum(p.numel() for p in arm_params) * 32  # assuming float32\n",
    "    total_network_rate += arm_params_bits\n",
    "    total_network_rate /= im_tensor.numel()\n",
    "    total_network_rate = float(total_network_rate)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Forward pass with no quantization noise\n",
    "        predicted_prior = quantized_coolchic.forward(\n",
    "            image=im_tensor,\n",
    "            quantizer_noise_type=\"none\",\n",
    "            quantizer_type=\"hardround\",\n",
    "            AC_MAX_VAL=-1,\n",
    "            flag_additional_outputs=False,\n",
    "        )\n",
    "        predicted_priors_rates = loss_function(\n",
    "            predicted_prior,\n",
    "            im_tensor,\n",
    "            rate_mlp_bpd=total_network_rate,\n",
    "            latent_multiplier=1.0,\n",
    "            channel_ranges=c_bitdepths,\n",
    "        )\n",
    "    print(\n",
    "        f\"Rate per module: {rate_per_module},\\n\",\n",
    "        f\"Final results after quantization: {predicted_priors_rates}\"\n",
    "    )\n",
    "    table.append(\n",
    "        {\n",
    "            \"Index\": img_index,\n",
    "            \"Loss\": predicted_priors_rates.loss.cpu().item(),\n",
    "            \"Rate NN\": predicted_priors_rates.rate_nn_bpd,\n",
    "            \"Rate Latent\": predicted_priors_rates.rate_latent_bpd,\n",
    "            \"Rate Img\": predicted_priors_rates.rate_img_bpd,\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3969ed27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LaTeX Table:\n",
      "\n",
      "\\begin{tabular}{lllll}\n",
      "Index & Loss & Rate NN & Rate Latent & Rate Img \\\\\n",
      "\\hline\n",
      "0 & 3.297 & 0.034 & 0.041 & 3.223 \\\\\n",
      "1 & 2.924 & 0.032 & 0.061 & 2.832 \\\\\n",
      "2 & 2.550 & 0.033 & 0.025 & 2.492 \\\\\n",
      "3 & 2.973 & 0.033 & 0.030 & 2.911 \\\\\n",
      "4 & 3.496 & 0.032 & 0.064 & 3.400 \\\\\n",
      "5 & 3.089 & 0.033 & 0.081 & 2.974 \\\\\n",
      "6 & 2.760 & 0.033 & 0.053 & 2.673 \\\\\n",
      "7 & 3.550 & 0.033 & 0.071 & 3.446 \\\\\n",
      "8 & 2.883 & 0.026 & 0.007 & 2.849 \\\\\n",
      "9 & 2.934 & 0.027 & 0.002 & 2.905 \\\\\n",
      "10 & 3.000 & 0.032 & 0.023 & 2.945 \\\\\n",
      "11 & 2.831 & 0.033 & 0.019 & 2.779 \\\\\n",
      "12 & 3.834 & 0.031 & 0.032 & 3.771 \\\\\n",
      "13 & 3.243 & 0.033 & 0.050 & 3.160 \\\\\n",
      "14 & 2.809 & 0.033 & 0.024 & 2.752 \\\\\n",
      "15 & 2.797 & 0.032 & 0.027 & 2.738 \\\\\n",
      "16 & 2.881 & 0.033 & 0.022 & 2.826 \\\\\n",
      "17 & 3.511 & 0.031 & 0.020 & 3.460 \\\\\n",
      "18 & 3.115 & 0.033 & 0.020 & 3.062 \\\\\n",
      "19 & 2.589 & 0.033 & 0.041 & 2.515 \\\\\n",
      "20 & 3.168 & 0.033 & 0.036 & 3.100 \\\\\n",
      "21 & 3.301 & 0.033 & 0.021 & 3.246 \\\\\n",
      "22 & 2.745 & 0.033 & 0.032 & 2.680 \\\\\n",
      "23 & 3.227 & 0.033 & 0.040 & 3.154 \\\\\n",
      "\\end{tabular}\n"
     ]
    }
   ],
   "source": [
    "def dict_list_to_latex_table(rows, floatfmt=\"{:.3f}\"):\n",
    "    \"\"\"\n",
    "    Convert a list of dicts into a LaTeX table string.\n",
    "    \n",
    "    Args:\n",
    "        rows (list of dict): All dicts must have the same keys.\n",
    "        floatfmt (str): Format string for floats, e.g. \"{:.4f}\".\n",
    "    \n",
    "    Returns:\n",
    "        str: LaTeX table.\n",
    "    \"\"\"\n",
    "    if not rows:\n",
    "        return \"\"\n",
    "\n",
    "    # Column names taken from dict keys\n",
    "    cols = list(rows[0].keys())\n",
    "\n",
    "    # Escape LaTeX special characters in column names\n",
    "    def escape(s):\n",
    "        repl = {\n",
    "            '%': r'\\%',\n",
    "            '&': r'\\&',\n",
    "            '_': r'\\_',\n",
    "        }\n",
    "        for k, v in repl.items():\n",
    "            s = s.replace(k, v)\n",
    "        return s\n",
    "\n",
    "    header = \" & \".join(escape(c) for c in cols) + r\" \\\\\"\n",
    "\n",
    "    # Build table rows\n",
    "    body_lines = []\n",
    "    for row in rows:\n",
    "        cells = []\n",
    "        for c in cols:\n",
    "            v = row[c]\n",
    "            if isinstance(v, float):\n",
    "                v = floatfmt.format(v)\n",
    "            cells.append(str(v))\n",
    "        body_lines.append(\" & \".join(cells) + r\" \\\\\")\n",
    "    \n",
    "    body = \"\\n\".join(body_lines)\n",
    "\n",
    "    # Combine into a LaTeX table\n",
    "    latex = (\n",
    "        \"\\\\begin{tabular}{%s}\\n\" % (\"l\" * len(cols)) +\n",
    "        header + \"\\n\\\\hline\\n\" +\n",
    "        body + \"\\n\\\\end{tabular}\"\n",
    "    )\n",
    "    return latex\n",
    "\n",
    "latex_table = dict_list_to_latex_table(table, floatfmt=\"{:.3f}\")\n",
    "print(\"\\nLaTeX Table:\\n\")\n",
    "print(latex_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7be54199",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Averages:\n",
      "Average Loss: 3.062713\n",
      "Average Rate NN: 0.032154\n",
      "Average Rate Latent: 0.035096\n",
      "Average Rate Img: 2.995463\n"
     ]
    }
   ],
   "source": [
    "average_loss = np.mean([row[\"Loss\"] for row in table])\n",
    "average_rate_nn = np.mean([row[\"Rate NN\"] for row in table])\n",
    "average_rate_latent = np.mean([row[\"Rate Latent\"] for row in table])\n",
    "average_rate_img = np.mean([row[\"Rate Img\"] for row in table])\n",
    "print(\"\\nAverages:\")\n",
    "print(f\"Average Loss: {average_loss:.6f}\")\n",
    "print(f\"Average Rate NN: {average_rate_nn:.6f}\")\n",
    "print(f\"Average Rate Latent: {average_rate_latent:.6f}\")\n",
    "print(f\"Average Rate Img: {average_rate_img:.6f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cool_chic_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
