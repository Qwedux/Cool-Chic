{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0b81455",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using model: 2025_11_22__16_44_29__trained_coolchic_kodak_kodim01_img_rate_3.2631609439849854.pth\n",
      "Converting image to YCoCg color space\n",
      "Best loss for module arm: Loss: 3.265453577041626, Rate NN: 0.0022328693885356188, Rate Latent: 0.04100216552615166, Rate Img: 3.2222185134887695\n",
      "3.2748959064483643 0.000244140625 0.000244140625\n",
      "3.2748055458068848 0.000244140625 0.00048828125\n",
      "3.27480149269104 0.000244140625 0.0009765625\n",
      "Best loss for module image_arm: Loss: 3.27480149269104, Rate NN: 0.0115797258913517, Rate Latent: 0.04100216552615166, Rate Img: 3.222219467163086\n",
      "Best loss for module synthesis: Loss: 11.666115760803223, Rate NN: 0.012819926254451275, Rate Latent: 0.04100216552615166, Rate Img: 11.612293243408203\n",
      "Best loss for module upsampling: Loss: 11.591690063476562, Rate NN: 0.0128936767578125, Rate Latent: 0.04100216552615166, Rate Img: 11.53779411315918\n",
      "\n",
      "Time quantize_model():  9.2 seconds\n",
      "\n",
      "Rate per module: {'arm': {'bias': tensor(159., device='cuda:0'), 'weight': tensor(2475., device='cuda:0')}, 'image_arm': {'bias': tensor(581., device='cuda:0'), 'weight': tensor(8856., device='cuda:0')}, 'upsampling': {'bias': tensor(12., device='cuda:0'), 'weight': tensor(75., device='cuda:0')}, 'synthesis': {'bias': tensor(238., device='cuda:0'), 'weight': tensor(2814., device='cuda:0')}},\n",
      " Final results after quantization: Loss: 11.615615844726562, Rate NN: 0.0368194580078125, Rate Latent: 0.04100216552615166, Rate Img: 11.53779411315918\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Stop after one iteration for testing.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 104\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m     92\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRate per module: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrate_per_module\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFinal results after quantization: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpredicted_priors_rates\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     94\u001b[0m )\n\u001b[1;32m     95\u001b[0m table\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m     96\u001b[0m     {\n\u001b[1;32m     97\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIndex\u001b[39m\u001b[38;5;124m\"\u001b[39m: img_index,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    102\u001b[0m     }\n\u001b[1;32m    103\u001b[0m )\n\u001b[0;32m--> 104\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStop after one iteration for testing.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mException\u001b[0m: Stop after one iteration for testing."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "\n",
    "if os.path.basename(os.getcwd()) == \"analysis\":\n",
    "    os.chdir(os.path.dirname(os.getcwd()))\n",
    "    sys.path.append(os.getcwd())\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from lossless.component.coolchic import CoolChicEncoder, CoolChicEncoderParameter\n",
    "from lossless.nnquant.quantizemodel import quantize_model\n",
    "from lossless.training.loss import loss_function\n",
    "from lossless.training.manager import ImageEncoderManager\n",
    "from lossless.util.config import args\n",
    "from lossless.util.image_loading import load_image_as_tensor\n",
    "from lossless.util.parsecli import (\n",
    "    change_n_out_synth,\n",
    "    get_coolchic_param_from_args,\n",
    "    get_manager_from_args,\n",
    ")\n",
    "\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "torch.set_float32_matmul_precision(\"high\")\n",
    "\n",
    "model_location_dir = \"../logs/full_runs/21_11_2025_YCoCg_with_fixed_colorregression/trained_models\"\n",
    "model_paths = os.listdir(model_location_dir)\n",
    "model_paths = sorted(model_paths, key=lambda x: int(x.split(\"_kodim\")[1].split(\"_\")[0]))\n",
    "\n",
    "table = []\n",
    "for img_index in range(len(model_paths)):\n",
    "    color_space = \"YCoCg\"\n",
    "    use_image_arm = True\n",
    "    print(f\"Using model: {model_paths[img_index]}\")\n",
    "\n",
    "    im_path = args[\"input\"][img_index]\n",
    "    im_tensor, c_bitdepths = load_image_as_tensor(im_path, device=\"cuda:0\", color_space=color_space)\n",
    "\n",
    "    # ==========================================================================================\n",
    "    # LOAD PRESETS, COOLCHIC PARAMETERS\n",
    "    # ==========================================================================================\n",
    "    image_encoder_manager = ImageEncoderManager(**get_manager_from_args(args))\n",
    "    encoder_param = CoolChicEncoderParameter(**get_coolchic_param_from_args(args, \"lossless\"))\n",
    "    encoder_param.set_image_size((im_tensor.shape[2], im_tensor.shape[3]))\n",
    "    encoder_param.layers_synthesis = change_n_out_synth(\n",
    "        encoder_param.layers_synthesis, args[\"output_dim_size\"]\n",
    "    )\n",
    "    encoder_param.use_image_arm = use_image_arm\n",
    "    coolchic = CoolChicEncoder(param=encoder_param)\n",
    "    coolchic.to_device(\"cuda:0\")\n",
    "    coolchic.load_state_dict(torch.load(os.path.join(model_location_dir, model_paths[img_index])))\n",
    "\n",
    "    # ==========================================================================================\n",
    "    # QUANTIZE AND EVALUATE\n",
    "    # ==========================================================================================\n",
    "    # technically we don't need quantization when working with uncompressed model\n",
    "    quantized_coolchic = CoolChicEncoder(param=encoder_param)\n",
    "    quantized_coolchic.to_device(\"cuda:0\")\n",
    "    quantized_coolchic.set_param(coolchic.get_param())\n",
    "    quantized_coolchic = quantize_model(\n",
    "        quantized_coolchic,\n",
    "        im_tensor,\n",
    "        image_encoder_manager,\n",
    "        None, # type:ignore\n",
    "        color_bitdepths=c_bitdepths,\n",
    "    )\n",
    "    rate_per_module, total_network_rate = quantized_coolchic.get_network_rate()\n",
    "    with torch.no_grad():\n",
    "        arm_params = list(quantized_coolchic.image_arm.parameters())\n",
    "        arm_params_bits = sum(p.numel() for p in arm_params) * 32  # assuming float32\n",
    "    total_network_rate += arm_params_bits\n",
    "    total_network_rate /= im_tensor.numel()\n",
    "    total_network_rate = float(total_network_rate)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Forward pass with no quantization noise\n",
    "        predicted_prior = quantized_coolchic.forward(\n",
    "            image=im_tensor,\n",
    "            quantizer_noise_type=\"none\",\n",
    "            quantizer_type=\"hardround\",\n",
    "            AC_MAX_VAL=-1,\n",
    "            flag_additional_outputs=False,\n",
    "        )\n",
    "        predicted_priors_rates = loss_function(\n",
    "            predicted_prior,\n",
    "            im_tensor,\n",
    "            rate_mlp_bpd=total_network_rate,\n",
    "            latent_multiplier=1.0,\n",
    "            channel_ranges=c_bitdepths,\n",
    "        )\n",
    "    print(\n",
    "        f\"Rate per module: {rate_per_module},\\n\",\n",
    "        f\"Final results after quantization: {predicted_priors_rates}\"\n",
    "    )\n",
    "    table.append(\n",
    "        {\n",
    "            \"Index\": img_index,\n",
    "            \"Loss\": predicted_priors_rates.loss.cpu().item(),\n",
    "            \"Rate NN\": predicted_priors_rates.rate_nn_bpd,\n",
    "            \"Rate Latent\": predicted_priors_rates.rate_latent_bpd,\n",
    "            \"Rate Img\": predicted_priors_rates.rate_img_bpd,\n",
    "        }\n",
    "    )\n",
    "    raise Exception(\"Stop after one iteration for testing.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3969ed27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LaTeX Table:\n",
      "\n",
      "\\begin{tabular}{lllll}\n",
      "Index & Loss & Rate NN & Rate Latent & Rate Img \\\\\n",
      "\\hline\n",
      "0 & 3.297 & 0.034 & 0.041 & 3.223 \\\\\n",
      "1 & 2.924 & 0.032 & 0.061 & 2.832 \\\\\n",
      "2 & 2.550 & 0.033 & 0.025 & 2.492 \\\\\n",
      "3 & 2.973 & 0.033 & 0.030 & 2.911 \\\\\n",
      "4 & 3.496 & 0.032 & 0.064 & 3.400 \\\\\n",
      "5 & 3.089 & 0.033 & 0.081 & 2.974 \\\\\n",
      "6 & 2.760 & 0.033 & 0.053 & 2.673 \\\\\n",
      "7 & 3.550 & 0.033 & 0.071 & 3.446 \\\\\n",
      "8 & 2.883 & 0.026 & 0.007 & 2.849 \\\\\n",
      "9 & 2.934 & 0.027 & 0.002 & 2.905 \\\\\n",
      "10 & 3.000 & 0.032 & 0.023 & 2.945 \\\\\n",
      "11 & 2.831 & 0.033 & 0.019 & 2.779 \\\\\n",
      "12 & 3.834 & 0.031 & 0.032 & 3.771 \\\\\n",
      "13 & 3.243 & 0.033 & 0.050 & 3.160 \\\\\n",
      "14 & 2.809 & 0.033 & 0.024 & 2.752 \\\\\n",
      "15 & 2.797 & 0.032 & 0.027 & 2.738 \\\\\n",
      "16 & 2.881 & 0.033 & 0.022 & 2.826 \\\\\n",
      "17 & 3.511 & 0.031 & 0.020 & 3.460 \\\\\n",
      "18 & 3.115 & 0.033 & 0.020 & 3.062 \\\\\n",
      "19 & 2.589 & 0.033 & 0.041 & 2.515 \\\\\n",
      "20 & 3.168 & 0.033 & 0.036 & 3.100 \\\\\n",
      "21 & 3.301 & 0.033 & 0.021 & 3.246 \\\\\n",
      "22 & 2.745 & 0.033 & 0.032 & 2.680 \\\\\n",
      "23 & 3.227 & 0.033 & 0.040 & 3.154 \\\\\n",
      "\\end{tabular}\n"
     ]
    }
   ],
   "source": [
    "def dict_list_to_latex_table(rows, floatfmt=\"{:.3f}\"):\n",
    "    \"\"\"\n",
    "    Convert a list of dicts into a LaTeX table string.\n",
    "    \n",
    "    Args:\n",
    "        rows (list of dict): All dicts must have the same keys.\n",
    "        floatfmt (str): Format string for floats, e.g. \"{:.4f}\".\n",
    "    \n",
    "    Returns:\n",
    "        str: LaTeX table.\n",
    "    \"\"\"\n",
    "    if not rows:\n",
    "        return \"\"\n",
    "\n",
    "    # Column names taken from dict keys\n",
    "    cols = list(rows[0].keys())\n",
    "\n",
    "    # Escape LaTeX special characters in column names\n",
    "    def escape(s):\n",
    "        repl = {\n",
    "            '%': r'\\%',\n",
    "            '&': r'\\&',\n",
    "            '_': r'\\_',\n",
    "        }\n",
    "        for k, v in repl.items():\n",
    "            s = s.replace(k, v)\n",
    "        return s\n",
    "\n",
    "    header = \" & \".join(escape(c) for c in cols) + r\" \\\\\"\n",
    "\n",
    "    # Build table rows\n",
    "    body_lines = []\n",
    "    for row in rows:\n",
    "        cells = []\n",
    "        for c in cols:\n",
    "            v = row[c]\n",
    "            if isinstance(v, float):\n",
    "                v = floatfmt.format(v)\n",
    "            cells.append(str(v))\n",
    "        body_lines.append(\" & \".join(cells) + r\" \\\\\")\n",
    "    \n",
    "    body = \"\\n\".join(body_lines)\n",
    "\n",
    "    # Combine into a LaTeX table\n",
    "    latex = (\n",
    "        \"\\\\begin{tabular}{%s}\\n\" % (\"l\" * len(cols)) +\n",
    "        header + \"\\n\\\\hline\\n\" +\n",
    "        body + \"\\n\\\\end{tabular}\"\n",
    "    )\n",
    "    return latex\n",
    "\n",
    "latex_table = dict_list_to_latex_table(table, floatfmt=\"{:.3f}\")\n",
    "print(\"\\nLaTeX Table:\\n\")\n",
    "print(latex_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7be54199",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Averages:\n",
      "Average Loss: 3.062713\n",
      "Average Rate NN: 0.032154\n",
      "Average Rate Latent: 0.035096\n",
      "Average Rate Img: 2.995463\n"
     ]
    }
   ],
   "source": [
    "average_loss = np.mean([row[\"Loss\"] for row in table])\n",
    "average_rate_nn = np.mean([row[\"Rate NN\"] for row in table])\n",
    "average_rate_latent = np.mean([row[\"Rate Latent\"] for row in table])\n",
    "average_rate_img = np.mean([row[\"Rate Img\"] for row in table])\n",
    "print(\"\\nAverages:\")\n",
    "print(f\"Average Loss: {average_loss:.6f}\")\n",
    "print(f\"Average Rate NN: {average_rate_nn:.6f}\")\n",
    "print(f\"Average Rate Latent: {average_rate_latent:.6f}\")\n",
    "print(f\"Average Rate Img: {average_rate_img:.6f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cool_chic_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
