{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39e32bdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/jakub/ETH/thesis/Cool-Chic/coolchic/../datasets/kodak/kodim01.png', '/home/jakub/ETH/thesis/Cool-Chic/coolchic/../datasets/kodak/kodim02.png', '/home/jakub/ETH/thesis/Cool-Chic/coolchic/../datasets/kodak/kodim03.png', '/home/jakub/ETH/thesis/Cool-Chic/coolchic/../datasets/kodak/kodim04.png', '/home/jakub/ETH/thesis/Cool-Chic/coolchic/../datasets/kodak/kodim05.png', '/home/jakub/ETH/thesis/Cool-Chic/coolchic/../datasets/kodak/kodim06.png', '/home/jakub/ETH/thesis/Cool-Chic/coolchic/../datasets/kodak/kodim07.png', '/home/jakub/ETH/thesis/Cool-Chic/coolchic/../datasets/kodak/kodim08.png', '/home/jakub/ETH/thesis/Cool-Chic/coolchic/../datasets/kodak/kodim09.png', '/home/jakub/ETH/thesis/Cool-Chic/coolchic/../datasets/kodak/kodim10.png', '/home/jakub/ETH/thesis/Cool-Chic/coolchic/../datasets/kodak/kodim11.png', '/home/jakub/ETH/thesis/Cool-Chic/coolchic/../datasets/kodak/kodim12.png', '/home/jakub/ETH/thesis/Cool-Chic/coolchic/../datasets/kodak/kodim13.png', '/home/jakub/ETH/thesis/Cool-Chic/coolchic/../datasets/kodak/kodim14.png', '/home/jakub/ETH/thesis/Cool-Chic/coolchic/../datasets/kodak/kodim15.png', '/home/jakub/ETH/thesis/Cool-Chic/coolchic/../datasets/kodak/kodim16.png', '/home/jakub/ETH/thesis/Cool-Chic/coolchic/../datasets/kodak/kodim17.png', '/home/jakub/ETH/thesis/Cool-Chic/coolchic/../datasets/kodak/kodim18.png', '/home/jakub/ETH/thesis/Cool-Chic/coolchic/../datasets/kodak/kodim19.png', '/home/jakub/ETH/thesis/Cool-Chic/coolchic/../datasets/kodak/kodim20.png', '/home/jakub/ETH/thesis/Cool-Chic/coolchic/../datasets/kodak/kodim21.png', '/home/jakub/ETH/thesis/Cool-Chic/coolchic/../datasets/kodak/kodim22.png', '/home/jakub/ETH/thesis/Cool-Chic/coolchic/../datasets/kodak/kodim23.png', '/home/jakub/ETH/thesis/Cool-Chic/coolchic/../datasets/kodak/kodim24.png']\n",
      "Converting image to YCoCg color space\n",
      "Arguments:\n",
      "  DATASET_PATH: /home/jakub/ETH/thesis/Cool-Chic/coolchic/../datasets/kodak/\n",
      "  TEST_WORKDIR: /home/jakub/ETH/thesis/Cool-Chic/coolchic/../coolchic/test-workdir/\n",
      "  LOG_PATH: /home/jakub/ETH/thesis/Cool-Chic/coolchic/../logs/\n",
      "  workdir: /home/jakub/ETH/thesis/Cool-Chic/coolchic/../coolchic/test-workdir/\n",
      "  lmbda: 0.001\n",
      "  job_duration_min: -1\n",
      "  print_detailed_archi: False\n",
      "  print_detailed_struct: False\n",
      "  start_lr: 0.01\n",
      "  n_itr: 500\n",
      "  n_train_loops: 1\n",
      "  preset: fnlic\n",
      "  layers_synthesis_residue: 24-1-linear-relu,X-1-linear-none,X-3-residual-relu,X-3-residual-none\n",
      "  arm_residue: 16,2\n",
      "  arm_image_context_size: 8\n",
      "  n_ft_per_res_residue: 1,1,1,1,1,1,1\n",
      "  ups_k_size_residue: 8\n",
      "  ups_preconcat_k_size_residue: 7\n",
      "  output_dim_size: 9\n",
      "  patience: 5000\n",
      "  schedule_lr: True\n",
      "  freq_valid: 100\n",
      "  optimized_module: ['all']\n",
      "  quantizer_type: softround\n",
      "  quantizer_noise_type: kumaraswamy\n",
      "  softround_temperature: (0.3, 0.1)\n",
      "  noise_parameter: (0.25, 0.1)\n",
      "  quantize_model: True\n",
      "\n",
      "Processing image /home/jakub/ETH/thesis/Cool-Chic/coolchic/../datasets/kodak/kodim01.png\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "os.chdir(os.path.dirname(os.getcwd()))\n",
    "sys.path.append(os.getcwd())\n",
    "\n",
    "import torch\n",
    "from lossless.component.coolchic import CoolChicEncoderParameter\n",
    "from lossless.component.coolchic import CoolChicEncoder\n",
    "from lossless.util.config import (\n",
    "    args, str_args\n",
    ")\n",
    "from lossless.util.parsecli import (\n",
    "    change_n_out_synth,\n",
    "    get_coolchic_param_from_args,\n",
    ")\n",
    "from lossless.util.image_loading import load_image_as_tensor\n",
    "from lossless.util.logger import TrainingLogger\n",
    "\n",
    "\n",
    "image_index = 0\n",
    "print(args[\"input\"])\n",
    "\n",
    "im_path = args[\"input\"][image_index]\n",
    "im_tensor, c_bitdepths = load_image_as_tensor(im_path, device=\"cuda:0\")\n",
    "dataset = im_path.split(\"/\")[-2]\n",
    "\n",
    "logger = TrainingLogger(\n",
    "    log_folder_path=args[\"LOG_PATH\"],\n",
    "    image_name=f\"{dataset}_\" + im_path.split(\"/\")[-1].split(\".\")[0],\n",
    ")\n",
    "logger.log_result(f\"{str_args(args)}\")\n",
    "logger.log_result(f\"Processing image {im_path}\")\n",
    "\n",
    "encoder_param = CoolChicEncoderParameter(\n",
    "    **get_coolchic_param_from_args(args, \"residue\")\n",
    ")\n",
    "encoder_param.set_image_size((im_tensor.shape[2], im_tensor.shape[3]))\n",
    "encoder_param.layers_synthesis = change_n_out_synth(\n",
    "    encoder_param.layers_synthesis, args[\"output_dim_size\"]\n",
    ")\n",
    "coolchic = CoolChicEncoder(param=encoder_param)\n",
    "coolchic.to_device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "649e71b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2126.3125\n",
      "| module                            | #parameters or shape   | #flops     |\n",
      "|:----------------------------------|:-----------------------|:-----------|\n",
      "| model                             | 0.526M                 | 0.836G     |\n",
      "|  latent_grids                     |  0.524M                |            |\n",
      "|   latent_grids.0                  |   (1, 1, 512, 768)     |            |\n",
      "|   latent_grids.1                  |   (1, 1, 256, 384)     |            |\n",
      "|   latent_grids.2                  |   (1, 1, 128, 192)     |            |\n",
      "|   latent_grids.3                  |   (1, 1, 64, 96)       |            |\n",
      "|   latent_grids.4                  |   (1, 1, 32, 48)       |            |\n",
      "|   latent_grids.5                  |   (1, 1, 16, 24)       |            |\n",
      "|   latent_grids.6                  |   (1, 1, 8, 12)        |            |\n",
      "|  synthesis.layers                 |  0.921K                |  0.342G    |\n",
      "|   synthesis.layers.0              |   0.192K               |   66.06M   |\n",
      "|    synthesis.layers.0.weight      |    (24, 7, 1, 1)       |            |\n",
      "|    synthesis.layers.0.bias        |    (24,)               |            |\n",
      "|   synthesis.layers.2              |   0.225K               |   84.935M  |\n",
      "|    synthesis.layers.2.weight      |    (9, 24, 1, 1)       |            |\n",
      "|    synthesis.layers.2.bias        |    (9,)                |            |\n",
      "|   synthesis.layers.4              |   0.252K               |   95.551M  |\n",
      "|    synthesis.layers.4.weight      |    (9, 3, 3, 3)        |            |\n",
      "|    synthesis.layers.4.bias        |    (9,)                |            |\n",
      "|   synthesis.layers.6              |   0.252K               |   95.551M  |\n",
      "|    synthesis.layers.6.weight      |    (9, 3, 3, 3)        |            |\n",
      "|    synthesis.layers.6.bias        |    (9,)                |            |\n",
      "|  upsampling                       |  60                    |  25.822M   |\n",
      "|   upsampling.conv_transpose2ds    |   30                   |   18.483M  |\n",
      "|    upsampling.conv_transpose2ds.0 |    5                   |    4.352K  |\n",
      "|    upsampling.conv_transpose2ds.1 |    5                   |    26.624K |\n",
      "|    upsampling.conv_transpose2ds.2 |    5                   |    0.135M  |\n",
      "|    upsampling.conv_transpose2ds.3 |    5                   |    0.655M  |\n",
      "|    upsampling.conv_transpose2ds.4 |    5                   |    3.113M  |\n",
      "|    upsampling.conv_transpose2ds.5 |    5                   |    14.549M |\n",
      "|   upsampling.conv2ds              |   30                   |   7.338M   |\n",
      "|    upsampling.conv2ds.0           |    5                   |    5.376K  |\n",
      "|    upsampling.conv2ds.1           |    5                   |    21.504K |\n",
      "|    upsampling.conv2ds.2           |    5                   |    86.016K |\n",
      "|    upsampling.conv2ds.3           |    5                   |    0.344M  |\n",
      "|    upsampling.conv2ds.4           |    5                   |    1.376M  |\n",
      "|    upsampling.conv2ds.5           |    5                   |    5.505M  |\n",
      "|  arm.mlp                          |  0.298K                |  0.143G    |\n",
      "|   arm.mlp.0                       |   0.136K               |   67.105M  |\n",
      "|    arm.mlp.0.weight               |    (8, 16)             |            |\n",
      "|    arm.mlp.0.bias                 |    (8,)                |            |\n",
      "|   arm.mlp.1                       |   72                   |   33.552M  |\n",
      "|    arm.mlp.1.weight               |    (8, 8)              |            |\n",
      "|    arm.mlp.1.bias                 |    (8,)                |            |\n",
      "|   arm.mlp.3                       |   72                   |   33.552M  |\n",
      "|    arm.mlp.3.weight               |    (8, 8)              |            |\n",
      "|    arm.mlp.3.bias                 |    (8,)                |            |\n",
      "|   arm.mlp.5                       |   18                   |   8.388M   |\n",
      "|    arm.mlp.5.weight               |    (2, 8)              |            |\n",
      "|    arm.mlp.5.bias                 |    (2,)                |            |\n",
      "|  image_arm.models                 |  0.882K                |  0.326G    |\n",
      "|   image_arm.models.0              |   0.274K               |   0.101G   |\n",
      "|    image_arm.models.0.0           |    0.204K              |    77.857M |\n",
      "|    image_arm.models.0.2           |    42                  |    14.156M |\n",
      "|    image_arm.models.0.4           |    28                  |    9.437M  |\n",
      "|   image_arm.models.1              |   0.294K               |   0.109G   |\n",
      "|    image_arm.models.1.0           |    0.21K               |    80.216M |\n",
      "|    image_arm.models.1.2           |    42                  |    14.156M |\n",
      "|    image_arm.models.1.4           |    42                  |    14.156M |\n",
      "|   image_arm.models.2              |   0.314K               |   0.116G   |\n",
      "|    image_arm.models.2.0           |    0.216K              |    82.575M |\n",
      "|    image_arm.models.2.2           |    42                  |    14.156M |\n",
      "|    image_arm.models.2.4           |    56                  |    18.874M |\n",
      "\n",
      "----------------------------------\n",
      "Total MAC / decoded pixel: 2126.3\n",
      "----------------------------------\n"
     ]
    }
   ],
   "source": [
    "# print(coolchic.get_flops())\n",
    "# print(coolchic.flops_str())\n",
    "with torch.no_grad():\n",
    "    print(coolchic.get_total_mac_per_pixel())\n",
    "    print(coolchic.str_complexity())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cool_chic_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
