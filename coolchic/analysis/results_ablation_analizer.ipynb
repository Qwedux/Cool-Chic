{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "389104ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time \n",
    "import datetime\n",
    "\n",
    "def print_table(data: dict[str, list[float]], precision: int = 4):\n",
    "    # Convert to list of keys and find number of rows\n",
    "    headers = list(data.keys())\n",
    "    headers = [\"index\"] + headers        \n",
    "    n_rows = len(next(iter(data.values())))\n",
    "    data[\"index\"] = list(range(1, n_rows+1))\n",
    "\n",
    "    # Format floats to desired precision\n",
    "    fmt = f\"{{:.{precision}f}}\"\n",
    "\n",
    "    # Compute column widths\n",
    "    col_widths = []\n",
    "    for h in headers:\n",
    "        values = data[h]\n",
    "        max_val_len = max(len(fmt.format(v)) for v in values)\n",
    "        col_widths.append(max(len(h), max_val_len))\n",
    "\n",
    "    # Build header row\n",
    "    header_row = \" | \".join(f\"{h:>{w}}\" for h, w in zip(headers, col_widths))\n",
    "    separator = \"-+-\".join(\"-\" * w for w in col_widths)\n",
    "\n",
    "    # Print table\n",
    "    print(header_row)\n",
    "    print(separator)\n",
    "    for i in range(n_rows):\n",
    "        row = \" | \".join(fmt.format(data[h][i]).rjust(w) for h, w in zip(headers, col_widths))\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b9c3d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dt_to_intkey(date_str: str, time_str: str) -> float:\n",
    "    dt = datetime.datetime.strptime(f\"{date_str} {time_str}\", \"%Y_%m_%d %H_%M_%S\")\n",
    "    return dt.timestamp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d02390bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24 files found after filtering.\n"
     ]
    }
   ],
   "source": [
    "data_dir = \"../../logs_cluster/logs/full_runs/2026_10_01_YCoCg_larger_imarm_two_by_two_Kodak/results/\"\n",
    "res_files_unfiltered = [f for f in os.listdir(data_dir) if f.endswith(\".log\")]\n",
    "res_files_unfiltered.sort()\n",
    "# print(*res_files_unfiltered, sep=\"\\n\")\n",
    "dates, times = zip(*(s.split(\"__\")[:2] for s in res_files_unfiltered))\n",
    "creation_times = {\n",
    "    # key is date_time string converted to int/float for sorting\n",
    "    index: dt_to_intkey(date, time)\n",
    "    for index, (date, time) in enumerate(zip(dates, times))\n",
    "}\n",
    "only_after = dt_to_intkey(\"2025_10_30\", \"00_00_00\")\n",
    "res_files = [\n",
    "    res_files_unfiltered[index]\n",
    "    for index, creation_time in creation_times.items()\n",
    "    if creation_time >= only_after\n",
    "]\n",
    "# print(*res_files, sep=\"\\n\")\n",
    "print(len(res_files), \"files found after filtering.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bae13cf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using color space: YCoCg\n",
      "Using Image ARM: True\n",
      "Using encoder gain: 64\n",
      "Using multi-region image ARM: True\n",
      "Using color regression: False\n",
      "Total training iterations: 142200\n",
      "Total MAC per pixel: 1988.3125\n",
      "  index |   Loss | Rate NN | Rate Latent | Rate Img\n",
      "--------+--------+---------+-------------+---------\n",
      " 1.0000 | 3.0812 |  0.1611 |      0.5132 |   2.4069\n",
      " 2.0000 | 3.4329 |  0.1598 |      0.1563 |   3.1168\n",
      " 3.0000 | 3.4652 |  0.1601 |      0.3336 |   2.9715\n",
      " 4.0000 | 3.1171 |  0.1597 |      0.2066 |   2.7508\n",
      " 5.0000 | 2.7559 |  0.1569 |      0.2143 |   2.3847\n",
      " 6.0000 | 2.5682 |  0.1660 |      0.0576 |   2.3446\n",
      " 7.0000 | 2.9921 |  0.1613 |      0.1990 |   2.6318\n",
      " 8.0000 | 3.6430 |  0.1603 |      0.2634 |   3.2193\n",
      " 9.0000 | 2.8757 |  0.1614 |      0.2306 |   2.4838\n",
      "10.0000 | 3.0392 |  0.1622 |      0.1232 |   2.7538\n",
      "11.0000 | 3.0488 |  0.1624 |      0.1840 |   2.7024\n",
      "12.0000 | 2.7664 |  0.1630 |      0.2279 |   2.3754\n",
      "13.0000 | 3.7852 |  0.1645 |      0.5507 |   3.0699\n",
      "14.0000 | 3.3332 |  0.1647 |      0.0840 |   3.0845\n",
      "15.0000 | 2.8726 |  0.1648 |      0.0870 |   2.6207\n",
      "16.0000 | 2.8034 |  0.1572 |      0.1902 |   2.4560\n",
      "17.0000 | 2.8901 |  0.1561 |      0.2332 |   2.5008\n",
      "18.0000 | 3.5443 |  0.1574 |      0.4827 |   2.9042\n",
      "19.0000 | 3.1689 |  0.1603 |      0.3738 |   2.6348\n",
      "20.0000 | 2.7118 |  0.1655 |      0.6222 |   1.9241\n",
      "21.0000 | 3.1758 |  0.1642 |      0.2672 |   2.7444\n",
      "22.0000 | 3.3503 |  0.1592 |      0.2987 |   2.8923\n",
      "23.0000 | 2.7771 |  0.1645 |      0.1335 |   2.4791\n",
      "24.0000 | 3.1752 |  0.1652 |      0.2692 |   2.7409\n",
      "Loss: 3.0989\n",
      "Rate NN: 0.1616\n",
      "Rate Latent: 0.2626\n",
      "Rate Img: 2.6747\n",
      "index: 12.5000\n"
     ]
    }
   ],
   "source": [
    "# Example log lines we are looking for:\n",
    "# Using color space YCoCg with bitdepths [8, 9, 9]\n",
    "# Using image ARM: True\n",
    "# Using encoder gain: 64\n",
    "# Using multi-region image ARM: True\n",
    "# Using color regression: False\n",
    "# Total training iterations: 142200\n",
    "# Total MAC per pixel: 1694.3125\n",
    "# Final results after quantization: Loss: 3.278064727783203, Rate NN: 0.11986033121744792, Rate Latent: 0.1637668013572693, Rate Img: 2.9944374561309814\n",
    "# Rate Img bistream: 7.751302083333333\n",
    "\n",
    "using_color_space = \"\"\n",
    "using_image_arm = False\n",
    "using_encoder_gain = 0\n",
    "using_multi_region_image_arm = False\n",
    "using_color_regression = False\n",
    "total_training_iterations = 0\n",
    "total_mac_per_pixel = 0.0\n",
    "final_results = []\n",
    "# rate_img_bistream = []\n",
    "\n",
    "with open(os.path.join(data_dir, res_files[0]), \"r\") as infile:\n",
    "    lines = infile.readlines()    \n",
    "    for line in lines:\n",
    "        if line.startswith(\"Using color space\"):\n",
    "            using_color_space = line[len(\"Using color space\") :].strip().split(\" with bitdepths\")[0]\n",
    "        if line.startswith(\"Using image ARM:\"):\n",
    "            using_image_arm = line[len(\"Using image ARM:\"):].strip() == \"True\"\n",
    "        if line.startswith(\"Using encoder gain:\"):\n",
    "            using_encoder_gain = int(line[len(\"Using encoder gain:\"):].strip())\n",
    "        if line.startswith(\"Using multi-region image ARM:\"):\n",
    "            using_multi_region_image_arm = line[len(\"Using multi-region image ARM:\"):].strip() == \"True\"\n",
    "        if line.startswith(\"Using color regression:\"):\n",
    "            using_color_regression = line[len(\"Using color regression:\"):].strip() == \"True\"\n",
    "        if line.startswith(\"Total training iterations:\"):\n",
    "            total_training_iterations = int(line[len(\"Total training iterations:\"):].strip())\n",
    "        if line.startswith(\"Total MAC per pixel:\"):\n",
    "            total_mac_per_pixel = float(line[len(\"Total MAC per pixel:\"):].strip())\n",
    "\n",
    "    if using_color_space == \"\":\n",
    "        print(f\"Could not determine color space for file {res_files[0]}, skipping.\")\n",
    "        raise ValueError(\"No color space found.\")\n",
    "print(\"Using color space:\", using_color_space)\n",
    "print(\"Using Image ARM:\", using_image_arm)\n",
    "print(\"Using encoder gain:\", using_encoder_gain)\n",
    "print(\"Using multi-region image ARM:\", using_multi_region_image_arm)\n",
    "print(\"Using color regression:\", using_color_regression)\n",
    "print(\"Total training iterations:\", total_training_iterations)\n",
    "print(\"Total MAC per pixel:\", total_mac_per_pixel)\n",
    "\n",
    "\n",
    "for f in res_files:\n",
    "    with open(os.path.join(data_dir, f), \"r\") as infile:\n",
    "        lines = infile.readlines()   \n",
    "\n",
    "        for line in lines:\n",
    "            # if line.startswith(\"Rate Img bistream:\"):\n",
    "            #     rate_img_bistream.append(float(line[len(\"Rate Img bistream:\"):].strip()))\n",
    "            if \"Final results after quantization\" in line:\n",
    "                parts = line[len(\"Final results after quantization:\") :].strip().split(\", \")\n",
    "                im_index = int(f.split(\"_\")[-1][len(\"kodim\") :][: -len(\".log\")]) - 1\n",
    "                final_results.append({})\n",
    "                for part in parts:\n",
    "                    key, value = part.split(\": \")\n",
    "                    final_results[-1][key] = float(value)\n",
    "\n",
    "# print(\"Rate Img bistreams:\", rate_img_bistream)\n",
    "# print(\"Final results collected:\", final_results)\n",
    "\n",
    "def list_dict_to_dict_list(\n",
    "    lst: list[dict[str, float]],\n",
    ") -> dict[str, list[float]]:\n",
    "    if not lst:\n",
    "        return {}\n",
    "    keys = lst[0].keys()\n",
    "    dict_list = {key: [] for key in keys}\n",
    "    for d in lst:\n",
    "        for key in keys:\n",
    "            dict_list[key].append(d.get(key, 0.0))\n",
    "    return dict_list\n",
    "\n",
    "results_table = list_dict_to_dict_list(final_results)\n",
    "# results_table[\"Rate Img bistream\"] = rate_img_bistream\n",
    "print_table(results_table)\n",
    "\n",
    "for key in results_table.keys():\n",
    "    # results_for_key = [d[0] for d in results_table[key]]\n",
    "    # results_for_key = list_dict_to_dict_list(results_for_key)\n",
    "\n",
    "    # print(f\"{key}, Using Image ARM: {using_image_arm} Results:\")\n",
    "    # for i in range(len(results_for_key['Loss'])):\n",
    "    #     results_for_key['Loss'][i] = results_for_key['Loss'][i] - results_for_key['Rate NN'][i]\n",
    "    #     results_for_key['Rate NN'][i] = results_for_key['Rate NN'][i] #/ (512 * 768 * 3)\n",
    "    #     results_for_key['Loss'][i] = results_for_key['Loss'][i] + results_for_key['Rate NN'][i]\n",
    "    # print_table(results_for_key)\n",
    "    # for key, values in results_for_key.items():\n",
    "    avg = sum(results_table[key]) / len(results_table[key]) if results_table[key] else 0\n",
    "    print(f\"{key}: {avg:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cool_chic_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
