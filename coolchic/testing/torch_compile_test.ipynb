{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb3803fc",
   "metadata": {},
   "source": [
    "# Short tests to figure out how to use torch.compile\n",
    "\n",
    "## basic usage\n",
    "\n",
    "based on this [tutorial](https://docs.pytorch.org/tutorials/intermediate/torch_compile_tutorial.html)\n",
    "\n",
    "```python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb20b302",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "torch.manual_seed(0)\n",
    "torch._logging.set_logs(graph_code=True)\n",
    "random_input = torch.randn(3, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f3f3c9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "V1224 15:01:16.498000 12061 torch/fx/passes/runtime_assert.py:118] [2/0] [__graph_code] TRACED GRAPH\n",
      "V1224 15:01:16.498000 12061 torch/fx/passes/runtime_assert.py:118] [2/0] [__graph_code]  ===== pre insert_deferred_runtime_asserts __compiled_fn_5 =====\n",
      "V1224 15:01:16.498000 12061 torch/fx/passes/runtime_assert.py:118] [2/0] [__graph_code]  <eval_with_key>.8 class GraphModule(torch.nn.Module):\n",
      "V1224 15:01:16.498000 12061 torch/fx/passes/runtime_assert.py:118] [2/0] [__graph_code]     def forward(self, L_x_: \"f32[3, 3]\"):\n",
      "V1224 15:01:16.498000 12061 torch/fx/passes/runtime_assert.py:118] [2/0] [__graph_code]         l_x_ = L_x_\n",
      "V1224 15:01:16.498000 12061 torch/fx/passes/runtime_assert.py:118] [2/0] [__graph_code]         \n",
      "V1224 15:01:16.498000 12061 torch/fx/passes/runtime_assert.py:118] [2/0] [__graph_code]          # File: /tmp/ipykernel_12061/1116440188.py:2 in foo, code: a = torch.sin(x)\n",
      "V1224 15:01:16.498000 12061 torch/fx/passes/runtime_assert.py:118] [2/0] [__graph_code]         a: \"f32[3, 3]\" = torch.sin(l_x_)\n",
      "V1224 15:01:16.498000 12061 torch/fx/passes/runtime_assert.py:118] [2/0] [__graph_code]         \n",
      "V1224 15:01:16.498000 12061 torch/fx/passes/runtime_assert.py:118] [2/0] [__graph_code]          # File: /tmp/ipykernel_12061/1116440188.py:3 in foo, code: b = torch.cos(y)\n",
      "V1224 15:01:16.498000 12061 torch/fx/passes/runtime_assert.py:118] [2/0] [__graph_code]         b: \"f32[3, 3]\" = torch.cos(l_x_);  l_x_ = None\n",
      "V1224 15:01:16.498000 12061 torch/fx/passes/runtime_assert.py:118] [2/0] [__graph_code]         \n",
      "V1224 15:01:16.498000 12061 torch/fx/passes/runtime_assert.py:118] [2/0] [__graph_code]          # File: /tmp/ipykernel_12061/1116440188.py:4 in foo, code: return a + b\n",
      "V1224 15:01:16.498000 12061 torch/fx/passes/runtime_assert.py:118] [2/0] [__graph_code]         add: \"f32[3, 3]\" = a + b;  a = b = None\n",
      "V1224 15:01:16.498000 12061 torch/fx/passes/runtime_assert.py:118] [2/0] [__graph_code]         return (add,)\n",
      "V1224 15:01:16.498000 12061 torch/fx/passes/runtime_assert.py:118] [2/0] [__graph_code]         \n",
      "V1224 15:01:16.498000 12061 torch/fx/passes/runtime_assert.py:118] [2/0] [__graph_code] \n",
      "V1224 15:01:16.500000 12061 torch/_dynamo/output_graph.py:1408] [2/0] [__graph_code] TRACED GRAPH\n",
      "V1224 15:01:16.500000 12061 torch/_dynamo/output_graph.py:1408] [2/0] [__graph_code]  ===== __compiled_fn_5 =====\n",
      "V1224 15:01:16.500000 12061 torch/_dynamo/output_graph.py:1408] [2/0] [__graph_code]  /home/jakub/ETH/2025_2026_fall/thesis/Cool-Chic/.venv/lib/python3.10/site-packages/torch/fx/_lazy_graph_module.py class GraphModule(torch.nn.Module):\n",
      "V1224 15:01:16.500000 12061 torch/_dynamo/output_graph.py:1408] [2/0] [__graph_code]     def forward(self, L_x_: \"f32[3, 3][3, 1]cpu\"):\n",
      "V1224 15:01:16.500000 12061 torch/_dynamo/output_graph.py:1408] [2/0] [__graph_code]         l_x_ = L_x_\n",
      "V1224 15:01:16.500000 12061 torch/_dynamo/output_graph.py:1408] [2/0] [__graph_code]         \n",
      "V1224 15:01:16.500000 12061 torch/_dynamo/output_graph.py:1408] [2/0] [__graph_code]          # File: /tmp/ipykernel_12061/1116440188.py:2 in foo, code: a = torch.sin(x)\n",
      "V1224 15:01:16.500000 12061 torch/_dynamo/output_graph.py:1408] [2/0] [__graph_code]         a: \"f32[3, 3][3, 1]cpu\" = torch.sin(l_x_)\n",
      "V1224 15:01:16.500000 12061 torch/_dynamo/output_graph.py:1408] [2/0] [__graph_code]         \n",
      "V1224 15:01:16.500000 12061 torch/_dynamo/output_graph.py:1408] [2/0] [__graph_code]          # File: /tmp/ipykernel_12061/1116440188.py:3 in foo, code: b = torch.cos(y)\n",
      "V1224 15:01:16.500000 12061 torch/_dynamo/output_graph.py:1408] [2/0] [__graph_code]         b: \"f32[3, 3][3, 1]cpu\" = torch.cos(l_x_);  l_x_ = None\n",
      "V1224 15:01:16.500000 12061 torch/_dynamo/output_graph.py:1408] [2/0] [__graph_code]         \n",
      "V1224 15:01:16.500000 12061 torch/_dynamo/output_graph.py:1408] [2/0] [__graph_code]          # File: /tmp/ipykernel_12061/1116440188.py:4 in foo, code: return a + b\n",
      "V1224 15:01:16.500000 12061 torch/_dynamo/output_graph.py:1408] [2/0] [__graph_code]         add: \"f32[3, 3][3, 1]cpu\" = a + b;  a = b = None\n",
      "V1224 15:01:16.500000 12061 torch/_dynamo/output_graph.py:1408] [2/0] [__graph_code]         return (add,)\n",
      "V1224 15:01:16.500000 12061 torch/_dynamo/output_graph.py:1408] [2/0] [__graph_code]         \n",
      "V1224 15:01:16.500000 12061 torch/_dynamo/output_graph.py:1408] [2/0] [__graph_code] \n",
      "V1224 15:01:16.527000 12061 torch/fx/passes/_tensorify_python_scalars.py:364] [2/0] [__graph_code] TRACED GRAPH\n",
      "V1224 15:01:16.527000 12061 torch/fx/passes/_tensorify_python_scalars.py:364] [2/0] [__graph_code]  ===== tensorify_python_scalars =====\n",
      "V1224 15:01:16.527000 12061 torch/fx/passes/_tensorify_python_scalars.py:364] [2/0] [__graph_code]  /home/jakub/ETH/2025_2026_fall/thesis/Cool-Chic/.venv/lib/python3.10/site-packages/torch/fx/_lazy_graph_module.py class <lambda>(torch.nn.Module):\n",
      "V1224 15:01:16.527000 12061 torch/fx/passes/_tensorify_python_scalars.py:364] [2/0] [__graph_code]     def forward(self, arg0_1: \"f32[3, 3]\"):\n",
      "V1224 15:01:16.527000 12061 torch/fx/passes/_tensorify_python_scalars.py:364] [2/0] [__graph_code]          # File: /tmp/ipykernel_12061/1116440188.py:2 in foo, code: a = torch.sin(x)\n",
      "V1224 15:01:16.527000 12061 torch/fx/passes/_tensorify_python_scalars.py:364] [2/0] [__graph_code]         sin: \"f32[3, 3]\" = torch.ops.aten.sin.default(arg0_1)\n",
      "V1224 15:01:16.527000 12061 torch/fx/passes/_tensorify_python_scalars.py:364] [2/0] [__graph_code]         \n",
      "V1224 15:01:16.527000 12061 torch/fx/passes/_tensorify_python_scalars.py:364] [2/0] [__graph_code]          # File: /tmp/ipykernel_12061/1116440188.py:3 in foo, code: b = torch.cos(y)\n",
      "V1224 15:01:16.527000 12061 torch/fx/passes/_tensorify_python_scalars.py:364] [2/0] [__graph_code]         cos: \"f32[3, 3]\" = torch.ops.aten.cos.default(arg0_1);  arg0_1 = None\n",
      "V1224 15:01:16.527000 12061 torch/fx/passes/_tensorify_python_scalars.py:364] [2/0] [__graph_code]         \n",
      "V1224 15:01:16.527000 12061 torch/fx/passes/_tensorify_python_scalars.py:364] [2/0] [__graph_code]          # File: /tmp/ipykernel_12061/1116440188.py:4 in foo, code: return a + b\n",
      "V1224 15:01:16.527000 12061 torch/fx/passes/_tensorify_python_scalars.py:364] [2/0] [__graph_code]         add: \"f32[3, 3]\" = torch.ops.aten.add.Tensor(sin, cos);  sin = cos = None\n",
      "V1224 15:01:16.527000 12061 torch/fx/passes/_tensorify_python_scalars.py:364] [2/0] [__graph_code]         return (add,)\n",
      "V1224 15:01:16.527000 12061 torch/fx/passes/_tensorify_python_scalars.py:364] [2/0] [__graph_code]         \n",
      "V1224 15:01:16.527000 12061 torch/fx/passes/_tensorify_python_scalars.py:364] [2/0] [__graph_code] \n",
      "V1224 15:01:18.654000 12061 torch/fx/passes/runtime_assert.py:118] [3/0] [__graph_code] TRACED GRAPH\n",
      "V1224 15:01:18.654000 12061 torch/fx/passes/runtime_assert.py:118] [3/0] [__graph_code]  ===== pre insert_deferred_runtime_asserts __compiled_fn_7 =====\n",
      "V1224 15:01:18.654000 12061 torch/fx/passes/runtime_assert.py:118] [3/0] [__graph_code]  <eval_with_key>.13 class GraphModule(torch.nn.Module):\n",
      "V1224 15:01:18.654000 12061 torch/fx/passes/runtime_assert.py:118] [3/0] [__graph_code]     def forward(self, L_x_: \"f32[3, 3]\"):\n",
      "V1224 15:01:18.654000 12061 torch/fx/passes/runtime_assert.py:118] [3/0] [__graph_code]         l_x_ = L_x_\n",
      "V1224 15:01:18.654000 12061 torch/fx/passes/runtime_assert.py:118] [3/0] [__graph_code]         \n",
      "V1224 15:01:18.654000 12061 torch/fx/passes/runtime_assert.py:118] [3/0] [__graph_code]          # File: /tmp/ipykernel_12061/1116440188.py:13 in opt_foo2, code: a = torch.sin(x)\n",
      "V1224 15:01:18.654000 12061 torch/fx/passes/runtime_assert.py:118] [3/0] [__graph_code]         a: \"f32[3, 3]\" = torch.sin(l_x_)\n",
      "V1224 15:01:18.654000 12061 torch/fx/passes/runtime_assert.py:118] [3/0] [__graph_code]         \n",
      "V1224 15:01:18.654000 12061 torch/fx/passes/runtime_assert.py:118] [3/0] [__graph_code]          # File: /tmp/ipykernel_12061/1116440188.py:14 in opt_foo2, code: b = torch.cos(y)\n",
      "V1224 15:01:18.654000 12061 torch/fx/passes/runtime_assert.py:118] [3/0] [__graph_code]         b: \"f32[3, 3]\" = torch.cos(l_x_);  l_x_ = None\n",
      "V1224 15:01:18.654000 12061 torch/fx/passes/runtime_assert.py:118] [3/0] [__graph_code]         \n",
      "V1224 15:01:18.654000 12061 torch/fx/passes/runtime_assert.py:118] [3/0] [__graph_code]          # File: /tmp/ipykernel_12061/1116440188.py:15 in opt_foo2, code: return a + b\n",
      "V1224 15:01:18.654000 12061 torch/fx/passes/runtime_assert.py:118] [3/0] [__graph_code]         add: \"f32[3, 3]\" = a + b;  a = b = None\n",
      "V1224 15:01:18.654000 12061 torch/fx/passes/runtime_assert.py:118] [3/0] [__graph_code]         return (add,)\n",
      "V1224 15:01:18.654000 12061 torch/fx/passes/runtime_assert.py:118] [3/0] [__graph_code]         \n",
      "V1224 15:01:18.654000 12061 torch/fx/passes/runtime_assert.py:118] [3/0] [__graph_code] \n",
      "V1224 15:01:18.656000 12061 torch/_dynamo/output_graph.py:1408] [3/0] [__graph_code] TRACED GRAPH\n",
      "V1224 15:01:18.656000 12061 torch/_dynamo/output_graph.py:1408] [3/0] [__graph_code]  ===== __compiled_fn_7 =====\n",
      "V1224 15:01:18.656000 12061 torch/_dynamo/output_graph.py:1408] [3/0] [__graph_code]  /home/jakub/ETH/2025_2026_fall/thesis/Cool-Chic/.venv/lib/python3.10/site-packages/torch/fx/_lazy_graph_module.py class GraphModule(torch.nn.Module):\n",
      "V1224 15:01:18.656000 12061 torch/_dynamo/output_graph.py:1408] [3/0] [__graph_code]     def forward(self, L_x_: \"f32[3, 3][3, 1]cpu\"):\n",
      "V1224 15:01:18.656000 12061 torch/_dynamo/output_graph.py:1408] [3/0] [__graph_code]         l_x_ = L_x_\n",
      "V1224 15:01:18.656000 12061 torch/_dynamo/output_graph.py:1408] [3/0] [__graph_code]         \n",
      "V1224 15:01:18.656000 12061 torch/_dynamo/output_graph.py:1408] [3/0] [__graph_code]          # File: /tmp/ipykernel_12061/1116440188.py:13 in opt_foo2, code: a = torch.sin(x)\n",
      "V1224 15:01:18.656000 12061 torch/_dynamo/output_graph.py:1408] [3/0] [__graph_code]         a: \"f32[3, 3][3, 1]cpu\" = torch.sin(l_x_)\n",
      "V1224 15:01:18.656000 12061 torch/_dynamo/output_graph.py:1408] [3/0] [__graph_code]         \n",
      "V1224 15:01:18.656000 12061 torch/_dynamo/output_graph.py:1408] [3/0] [__graph_code]          # File: /tmp/ipykernel_12061/1116440188.py:14 in opt_foo2, code: b = torch.cos(y)\n",
      "V1224 15:01:18.656000 12061 torch/_dynamo/output_graph.py:1408] [3/0] [__graph_code]         b: \"f32[3, 3][3, 1]cpu\" = torch.cos(l_x_);  l_x_ = None\n",
      "V1224 15:01:18.656000 12061 torch/_dynamo/output_graph.py:1408] [3/0] [__graph_code]         \n",
      "V1224 15:01:18.656000 12061 torch/_dynamo/output_graph.py:1408] [3/0] [__graph_code]          # File: /tmp/ipykernel_12061/1116440188.py:15 in opt_foo2, code: return a + b\n",
      "V1224 15:01:18.656000 12061 torch/_dynamo/output_graph.py:1408] [3/0] [__graph_code]         add: \"f32[3, 3][3, 1]cpu\" = a + b;  a = b = None\n",
      "V1224 15:01:18.656000 12061 torch/_dynamo/output_graph.py:1408] [3/0] [__graph_code]         return (add,)\n",
      "V1224 15:01:18.656000 12061 torch/_dynamo/output_graph.py:1408] [3/0] [__graph_code]         \n",
      "V1224 15:01:18.656000 12061 torch/_dynamo/output_graph.py:1408] [3/0] [__graph_code] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.0294,  0.6680, -1.3920],\n",
      "        [ 1.3811, -0.4167, -0.8139],\n",
      "        [ 1.3123,  1.4123,  0.0935]])\n",
      "tensor([[ 1.0294,  0.6680, -1.3920],\n",
      "        [ 1.3811, -0.4167, -0.8139],\n",
      "        [ 1.3123,  1.4123,  0.0935]])\n"
     ]
    }
   ],
   "source": [
    "def foo(x, y):\n",
    "    a = torch.sin(x)\n",
    "    b = torch.cos(y)\n",
    "    return a + b\n",
    "\n",
    "\n",
    "opt_foo1 = torch.compile(foo)\n",
    "print(opt_foo1(random_input, random_input))\n",
    "\n",
    "\n",
    "@torch.compile\n",
    "def opt_foo2(x, y):\n",
    "    a = torch.sin(x)\n",
    "    b = torch.cos(y)\n",
    "    return a + b\n",
    "\n",
    "\n",
    "print(opt_foo2(random_input, random_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e41b8485",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "V1224 15:02:56.304000 12061 torch/fx/passes/runtime_assert.py:118] [4/0] [__graph_code] TRACED GRAPH\n",
      "V1224 15:02:56.304000 12061 torch/fx/passes/runtime_assert.py:118] [4/0] [__graph_code]  ===== pre insert_deferred_runtime_asserts __compiled_fn_9 =====\n",
      "V1224 15:02:56.304000 12061 torch/fx/passes/runtime_assert.py:118] [4/0] [__graph_code]  <eval_with_key>.16 class GraphModule(torch.nn.Module):\n",
      "V1224 15:02:56.304000 12061 torch/fx/passes/runtime_assert.py:118] [4/0] [__graph_code]     def forward(self, L_x_: \"f32[4096, 4096]\"):\n",
      "V1224 15:02:56.304000 12061 torch/fx/passes/runtime_assert.py:118] [4/0] [__graph_code]         l_x_ = L_x_\n",
      "V1224 15:02:56.304000 12061 torch/fx/passes/runtime_assert.py:118] [4/0] [__graph_code]         \n",
      "V1224 15:02:56.304000 12061 torch/fx/passes/runtime_assert.py:118] [4/0] [__graph_code]          # File: /tmp/ipykernel_12061/2208011240.py:2 in foo3, code: y = x + 1\n",
      "V1224 15:02:56.304000 12061 torch/fx/passes/runtime_assert.py:118] [4/0] [__graph_code]         y: \"f32[4096, 4096]\" = l_x_ + 1;  l_x_ = None\n",
      "V1224 15:02:56.304000 12061 torch/fx/passes/runtime_assert.py:118] [4/0] [__graph_code]         \n",
      "V1224 15:02:56.304000 12061 torch/fx/passes/runtime_assert.py:118] [4/0] [__graph_code]          # File: /tmp/ipykernel_12061/2208011240.py:3 in foo3, code: z = torch.nn.functional.relu(y)\n",
      "V1224 15:02:56.304000 12061 torch/fx/passes/runtime_assert.py:118] [4/0] [__graph_code]         z: \"f32[4096, 4096]\" = torch.nn.functional.relu(y);  y = None\n",
      "V1224 15:02:56.304000 12061 torch/fx/passes/runtime_assert.py:118] [4/0] [__graph_code]         \n",
      "V1224 15:02:56.304000 12061 torch/fx/passes/runtime_assert.py:118] [4/0] [__graph_code]          # File: /tmp/ipykernel_12061/2208011240.py:4 in foo3, code: u = z * 2\n",
      "V1224 15:02:56.304000 12061 torch/fx/passes/runtime_assert.py:118] [4/0] [__graph_code]         u: \"f32[4096, 4096]\" = z * 2;  z = None\n",
      "V1224 15:02:56.304000 12061 torch/fx/passes/runtime_assert.py:118] [4/0] [__graph_code]         return (u,)\n",
      "V1224 15:02:56.304000 12061 torch/fx/passes/runtime_assert.py:118] [4/0] [__graph_code]         \n",
      "V1224 15:02:56.304000 12061 torch/fx/passes/runtime_assert.py:118] [4/0] [__graph_code] \n",
      "V1224 15:02:56.305000 12061 torch/_dynamo/output_graph.py:1408] [4/0] [__graph_code] TRACED GRAPH\n",
      "V1224 15:02:56.305000 12061 torch/_dynamo/output_graph.py:1408] [4/0] [__graph_code]  ===== __compiled_fn_9 =====\n",
      "V1224 15:02:56.305000 12061 torch/_dynamo/output_graph.py:1408] [4/0] [__graph_code]  /home/jakub/ETH/2025_2026_fall/thesis/Cool-Chic/.venv/lib/python3.10/site-packages/torch/fx/_lazy_graph_module.py class GraphModule(torch.nn.Module):\n",
      "V1224 15:02:56.305000 12061 torch/_dynamo/output_graph.py:1408] [4/0] [__graph_code]     def forward(self, L_x_: \"f32[4096, 4096][4096, 1]cuda:0\"):\n",
      "V1224 15:02:56.305000 12061 torch/_dynamo/output_graph.py:1408] [4/0] [__graph_code]         l_x_ = L_x_\n",
      "V1224 15:02:56.305000 12061 torch/_dynamo/output_graph.py:1408] [4/0] [__graph_code]         \n",
      "V1224 15:02:56.305000 12061 torch/_dynamo/output_graph.py:1408] [4/0] [__graph_code]          # File: /tmp/ipykernel_12061/2208011240.py:2 in foo3, code: y = x + 1\n",
      "V1224 15:02:56.305000 12061 torch/_dynamo/output_graph.py:1408] [4/0] [__graph_code]         y: \"f32[4096, 4096][4096, 1]cuda:0\" = l_x_ + 1;  l_x_ = None\n",
      "V1224 15:02:56.305000 12061 torch/_dynamo/output_graph.py:1408] [4/0] [__graph_code]         \n",
      "V1224 15:02:56.305000 12061 torch/_dynamo/output_graph.py:1408] [4/0] [__graph_code]          # File: /tmp/ipykernel_12061/2208011240.py:3 in foo3, code: z = torch.nn.functional.relu(y)\n",
      "V1224 15:02:56.305000 12061 torch/_dynamo/output_graph.py:1408] [4/0] [__graph_code]         z: \"f32[4096, 4096][4096, 1]cuda:0\" = torch.nn.functional.relu(y);  y = None\n",
      "V1224 15:02:56.305000 12061 torch/_dynamo/output_graph.py:1408] [4/0] [__graph_code]         \n",
      "V1224 15:02:56.305000 12061 torch/_dynamo/output_graph.py:1408] [4/0] [__graph_code]          # File: /tmp/ipykernel_12061/2208011240.py:4 in foo3, code: u = z * 2\n",
      "V1224 15:02:56.305000 12061 torch/_dynamo/output_graph.py:1408] [4/0] [__graph_code]         u: \"f32[4096, 4096][4096, 1]cuda:0\" = z * 2;  z = None\n",
      "V1224 15:02:56.305000 12061 torch/_dynamo/output_graph.py:1408] [4/0] [__graph_code]         return (u,)\n",
      "V1224 15:02:56.305000 12061 torch/_dynamo/output_graph.py:1408] [4/0] [__graph_code]         \n",
      "V1224 15:02:56.305000 12061 torch/_dynamo/output_graph.py:1408] [4/0] [__graph_code] \n",
      "V1224 15:02:56.331000 12061 torch/fx/passes/_tensorify_python_scalars.py:364] [4/0] [__graph_code] TRACED GRAPH\n",
      "V1224 15:02:56.331000 12061 torch/fx/passes/_tensorify_python_scalars.py:364] [4/0] [__graph_code]  ===== tensorify_python_scalars =====\n",
      "V1224 15:02:56.331000 12061 torch/fx/passes/_tensorify_python_scalars.py:364] [4/0] [__graph_code]  /home/jakub/ETH/2025_2026_fall/thesis/Cool-Chic/.venv/lib/python3.10/site-packages/torch/fx/_lazy_graph_module.py class <lambda>(torch.nn.Module):\n",
      "V1224 15:02:56.331000 12061 torch/fx/passes/_tensorify_python_scalars.py:364] [4/0] [__graph_code]     def forward(self, arg0_1: \"f32[4096, 4096]\"):\n",
      "V1224 15:02:56.331000 12061 torch/fx/passes/_tensorify_python_scalars.py:364] [4/0] [__graph_code]          # File: /tmp/ipykernel_12061/2208011240.py:2 in foo3, code: y = x + 1\n",
      "V1224 15:02:56.331000 12061 torch/fx/passes/_tensorify_python_scalars.py:364] [4/0] [__graph_code]         add: \"f32[4096, 4096]\" = torch.ops.aten.add.Tensor(arg0_1, 1);  arg0_1 = None\n",
      "V1224 15:02:56.331000 12061 torch/fx/passes/_tensorify_python_scalars.py:364] [4/0] [__graph_code]         \n",
      "V1224 15:02:56.331000 12061 torch/fx/passes/_tensorify_python_scalars.py:364] [4/0] [__graph_code]          # File: /tmp/ipykernel_12061/2208011240.py:3 in foo3, code: z = torch.nn.functional.relu(y)\n",
      "V1224 15:02:56.331000 12061 torch/fx/passes/_tensorify_python_scalars.py:364] [4/0] [__graph_code]         relu: \"f32[4096, 4096]\" = torch.ops.aten.relu.default(add);  add = None\n",
      "V1224 15:02:56.331000 12061 torch/fx/passes/_tensorify_python_scalars.py:364] [4/0] [__graph_code]         \n",
      "V1224 15:02:56.331000 12061 torch/fx/passes/_tensorify_python_scalars.py:364] [4/0] [__graph_code]          # File: /tmp/ipykernel_12061/2208011240.py:4 in foo3, code: u = z * 2\n",
      "V1224 15:02:56.331000 12061 torch/fx/passes/_tensorify_python_scalars.py:364] [4/0] [__graph_code]         mul: \"f32[4096, 4096]\" = torch.ops.aten.mul.Tensor(relu, 2);  relu = None\n",
      "V1224 15:02:56.331000 12061 torch/fx/passes/_tensorify_python_scalars.py:364] [4/0] [__graph_code]         return (mul,)\n",
      "V1224 15:02:56.331000 12061 torch/fx/passes/_tensorify_python_scalars.py:364] [4/0] [__graph_code]         \n",
      "V1224 15:02:56.331000 12061 torch/fx/passes/_tensorify_python_scalars.py:364] [4/0] [__graph_code] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compile: 0.8350673217773438\n",
      "eager: 0.0952995834350586\n"
     ]
    }
   ],
   "source": [
    "def foo3(x):\n",
    "    y = x + 1\n",
    "    z = torch.nn.functional.relu(y)\n",
    "    u = z * 2\n",
    "    return u\n",
    "\n",
    "\n",
    "opt_foo3 = torch.compile(foo3)\n",
    "\n",
    "\n",
    "# Returns the result of running `fn()` and the time it took for `fn()` to run,\n",
    "# in seconds. We use CUDA events and synchronization for the most accurate\n",
    "# measurements.\n",
    "def timed(fn):\n",
    "    start = torch.cuda.Event(enable_timing=True)\n",
    "    end = torch.cuda.Event(enable_timing=True)\n",
    "    start.record()\n",
    "    result = fn()\n",
    "    end.record()\n",
    "    torch.cuda.synchronize()\n",
    "    return result, start.elapsed_time(end) / 1000\n",
    "\n",
    "\n",
    "inp = torch.randn(4096, 4096).cuda()\n",
    "print(\"compile:\", timed(lambda: opt_foo3(inp))[1])\n",
    "print(\"eager:\", timed(lambda: foo3(inp))[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc711685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eager time 0: 0.020702207565307617\n",
      "eager time 1: 0.023580671310424805\n",
      "eager time 2: 0.0192174072265625\n",
      "eager time 3: 0.020316160202026368\n",
      "eager time 4: 0.021369855880737306\n",
      "eager time 5: 0.02023219108581543\n",
      "eager time 6: 0.020067327499389647\n",
      "eager time 7: 0.02007347106933594\n",
      "eager time 8: 0.021485567092895508\n",
      "eager time 9: 0.020282367706298828\n",
      "~~~~~~~~~~\n",
      "compile time 0: 0.009602047920227052\n",
      "compile time 1: 0.006400000095367431\n",
      "compile time 2: 0.006756351947784424\n",
      "compile time 3: 0.007633920192718506\n",
      "compile time 4: 0.007480319976806641\n",
      "compile time 5: 0.007010303974151612\n",
      "compile time 6: 0.00790118408203125\n",
      "compile time 7: 0.006790143966674805\n",
      "compile time 8: 0.006490111827850342\n",
      "compile time 9: 0.00652185583114624\n",
      "~~~~~~~~~~\n",
      "(eval) eager median: 0.020299263954162598, compile median: 0.006900223970413209, speedup: 2.9418268220280694x\n",
      "~~~~~~~~~~\n"
     ]
    }
   ],
   "source": [
    "# turn off logging for now to prevent spam\n",
    "torch._logging.set_logs(graph_code=False)\n",
    "\n",
    "eager_times = []\n",
    "for i in range(10):\n",
    "    _, eager_time = timed(lambda: foo3(inp))\n",
    "    eager_times.append(eager_time)\n",
    "    print(f\"eager time {i}: {eager_time}\")\n",
    "print(\"~\" * 10)\n",
    "\n",
    "compile_times = []\n",
    "for i in range(10):\n",
    "    _, compile_time = timed(lambda: opt_foo3(inp))\n",
    "    compile_times.append(compile_time)\n",
    "    print(f\"compile time {i}: {compile_time}\")\n",
    "print(\"~\" * 10)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "eager_med = np.median(eager_times)\n",
    "compile_med = np.median(compile_times)\n",
    "speedup = eager_med / compile_med\n",
    "assert speedup > 1\n",
    "print(\n",
    "    f\"(eval) eager median: {eager_med}, compile median: {compile_med}, speedup: {speedup}x\"\n",
    ")\n",
    "print(\"~\" * 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3984107",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12061/65032246.py:2: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if x.sum() < 0:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "traced 1, 1: True\n",
      "traced 1, 2: False\n",
      "compile 1, 1: True\n",
      "compile 1, 2: True\n",
      "~~~~~~~~~~\n"
     ]
    }
   ],
   "source": [
    "def f1(x, y):\n",
    "    if x.sum() < 0:\n",
    "        return -y\n",
    "    return y\n",
    "\n",
    "\n",
    "# Test that `fn1` and `fn2` return the same result, given the same arguments `args`.\n",
    "def test_fns(fn1, fn2, args):\n",
    "    out1 = fn1(*args)\n",
    "    out2 = fn2(*args)\n",
    "    return torch.allclose(out1, out2)\n",
    "\n",
    "\n",
    "inp1 = torch.randn(5, 5)\n",
    "inp2 = torch.randn(5, 5)\n",
    "\n",
    "traced_f1 = torch.jit.trace(f1, (inp1, inp2))\n",
    "print(\"traced 1, 1:\", test_fns(f1, traced_f1, (inp1, inp2)))\n",
    "print(\"traced 1, 2:\", test_fns(f1, traced_f1, (-inp1, inp2)))\n",
    "\n",
    "compile_f1 = torch.compile(f1)\n",
    "print(\"compile 1, 1:\", test_fns(f1, compile_f1, (inp1, inp2)))\n",
    "print(\"compile 1, 2:\", test_fns(f1, compile_f1, (-inp1, inp2)))\n",
    "print(\"~\" * 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ebf63b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_12061/3652677659.py\", line 15, in <module>\n",
      "    script_f2(inp1, inp2)\n",
      "RuntimeError: f2() Expected a value of type 'Tensor (inferred)' for argument 'y' but instead found type 'int'.\n",
      "Inferred 'y' to be of type 'Tensor' because it was not annotated with an explicit type.\n",
      "Position: 1\n",
      "Value: 3\n",
      "Declaration: f2(Tensor x, Tensor y) -> Tensor\n",
      "Cast error details: Unable to cast 3 to Tensor\n",
      "V1224 15:10:02.253000 12061 torch/fx/passes/runtime_assert.py:118] [8/0] [__graph_code] TRACED GRAPH\n",
      "V1224 15:10:02.253000 12061 torch/fx/passes/runtime_assert.py:118] [8/0] [__graph_code]  ===== pre insert_deferred_runtime_asserts __compiled_fn_18 =====\n",
      "V1224 15:10:02.253000 12061 torch/fx/passes/runtime_assert.py:118] [8/0] [__graph_code]  <eval_with_key>.31 class GraphModule(torch.nn.Module):\n",
      "V1224 15:10:02.253000 12061 torch/fx/passes/runtime_assert.py:118] [8/0] [__graph_code]     def forward(self, L_x_: \"f32[5, 5]\"):\n",
      "V1224 15:10:02.253000 12061 torch/fx/passes/runtime_assert.py:118] [8/0] [__graph_code]         l_x_ = L_x_\n",
      "V1224 15:10:02.253000 12061 torch/fx/passes/runtime_assert.py:118] [8/0] [__graph_code]         \n",
      "V1224 15:10:02.253000 12061 torch/fx/passes/runtime_assert.py:118] [8/0] [__graph_code]          # File: /tmp/ipykernel_12061/3652677659.py:7 in f2, code: return x + y\n",
      "V1224 15:10:02.253000 12061 torch/fx/passes/runtime_assert.py:118] [8/0] [__graph_code]         add: \"f32[5, 5]\" = l_x_ + 3;  l_x_ = None\n",
      "V1224 15:10:02.253000 12061 torch/fx/passes/runtime_assert.py:118] [8/0] [__graph_code]         return (add,)\n",
      "V1224 15:10:02.253000 12061 torch/fx/passes/runtime_assert.py:118] [8/0] [__graph_code]         \n",
      "V1224 15:10:02.253000 12061 torch/fx/passes/runtime_assert.py:118] [8/0] [__graph_code] \n",
      "V1224 15:10:02.255000 12061 torch/_dynamo/output_graph.py:1408] [8/0] [__graph_code] TRACED GRAPH\n",
      "V1224 15:10:02.255000 12061 torch/_dynamo/output_graph.py:1408] [8/0] [__graph_code]  ===== __compiled_fn_18 =====\n",
      "V1224 15:10:02.255000 12061 torch/_dynamo/output_graph.py:1408] [8/0] [__graph_code]  /home/jakub/ETH/2025_2026_fall/thesis/Cool-Chic/.venv/lib/python3.10/site-packages/torch/fx/_lazy_graph_module.py class GraphModule(torch.nn.Module):\n",
      "V1224 15:10:02.255000 12061 torch/_dynamo/output_graph.py:1408] [8/0] [__graph_code]     def forward(self, L_x_: \"f32[5, 5][5, 1]cpu\"):\n",
      "V1224 15:10:02.255000 12061 torch/_dynamo/output_graph.py:1408] [8/0] [__graph_code]         l_x_ = L_x_\n",
      "V1224 15:10:02.255000 12061 torch/_dynamo/output_graph.py:1408] [8/0] [__graph_code]         \n",
      "V1224 15:10:02.255000 12061 torch/_dynamo/output_graph.py:1408] [8/0] [__graph_code]          # File: /tmp/ipykernel_12061/3652677659.py:7 in f2, code: return x + y\n",
      "V1224 15:10:02.255000 12061 torch/_dynamo/output_graph.py:1408] [8/0] [__graph_code]         add: \"f32[5, 5][5, 1]cpu\" = l_x_ + 3;  l_x_ = None\n",
      "V1224 15:10:02.255000 12061 torch/_dynamo/output_graph.py:1408] [8/0] [__graph_code]         return (add,)\n",
      "V1224 15:10:02.255000 12061 torch/_dynamo/output_graph.py:1408] [8/0] [__graph_code]         \n",
      "V1224 15:10:02.255000 12061 torch/_dynamo/output_graph.py:1408] [8/0] [__graph_code] \n",
      "V1224 15:10:02.279000 12061 torch/fx/passes/_tensorify_python_scalars.py:364] [8/0] [__graph_code] TRACED GRAPH\n",
      "V1224 15:10:02.279000 12061 torch/fx/passes/_tensorify_python_scalars.py:364] [8/0] [__graph_code]  ===== tensorify_python_scalars =====\n",
      "V1224 15:10:02.279000 12061 torch/fx/passes/_tensorify_python_scalars.py:364] [8/0] [__graph_code]  /home/jakub/ETH/2025_2026_fall/thesis/Cool-Chic/.venv/lib/python3.10/site-packages/torch/fx/_lazy_graph_module.py class <lambda>(torch.nn.Module):\n",
      "V1224 15:10:02.279000 12061 torch/fx/passes/_tensorify_python_scalars.py:364] [8/0] [__graph_code]     def forward(self, arg0_1: \"f32[5, 5]\"):\n",
      "V1224 15:10:02.279000 12061 torch/fx/passes/_tensorify_python_scalars.py:364] [8/0] [__graph_code]          # File: /tmp/ipykernel_12061/3652677659.py:7 in f2, code: return x + y\n",
      "V1224 15:10:02.279000 12061 torch/fx/passes/_tensorify_python_scalars.py:364] [8/0] [__graph_code]         add: \"f32[5, 5]\" = torch.ops.aten.add.Tensor(arg0_1, 3);  arg0_1 = None\n",
      "V1224 15:10:02.279000 12061 torch/fx/passes/_tensorify_python_scalars.py:364] [8/0] [__graph_code]         return (add,)\n",
      "V1224 15:10:02.279000 12061 torch/fx/passes/_tensorify_python_scalars.py:364] [8/0] [__graph_code]         \n",
      "V1224 15:10:02.279000 12061 torch/fx/passes/_tensorify_python_scalars.py:364] [8/0] [__graph_code] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compile 2: True\n",
      "~~~~~~~~~~\n"
     ]
    }
   ],
   "source": [
    "import traceback as tb\n",
    "\n",
    "torch._logging.set_logs(graph_code=True)\n",
    "\n",
    "\n",
    "def f2(x, y):\n",
    "    return x + y\n",
    "\n",
    "\n",
    "inp1 = torch.randn(5, 5)\n",
    "inp2 = 3\n",
    "\n",
    "script_f2 = torch.jit.script(f2)\n",
    "try:\n",
    "    script_f2(inp1, inp2)\n",
    "except:\n",
    "    tb.print_exc()\n",
    "\n",
    "compile_f2 = torch.compile(f2)\n",
    "print(\"compile 2:\", test_fns(f2, compile_f2, (inp1, inp2)))\n",
    "print(\"~\" * 10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
